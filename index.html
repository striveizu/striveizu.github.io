<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><link rel="icon" href="/images/icons/favicon-16x16.png?v=2.6.2" type="image/png" sizes="16x16"><link rel="icon" href="/images/icons/favicon-32x32.png?v=2.6.2" type="image/png" sizes="32x32"><meta property="og:type" content="website">
<meta property="og:title" content="Strive&#39;s Blog">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="Strive&#39;s Blog">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Strive">
<meta name="twitter:card" content="summary"><title>Strive's Blog</title><link ref="canonical" href="http://example.com/index.html"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.12.1/css/all.min.css" type="text/css"><link rel="stylesheet" href="/css/index.css?v=2.6.2"><script>var Stun = window.Stun || {};
var CONFIG = {
  root: '/',
  algolia: undefined,
  assistSearch: undefined,
  fontIcon: {"prompt":{"success":"fas fa-check-circle","info":"fas fa-arrow-circle-right","warning":"fas fa-exclamation-circle","error":"fas fa-times-circle"},"copyBtn":"fas fa-copy"},
  sidebar: {"offsetTop":"20px","tocMaxDepth":6},
  header: {"enable":true,"showOnPost":true,"scrollDownIcon":true},
  postWidget: {"endText":true},
  nightMode: {"enable":true},
  back2top: {"enable":true},
  codeblock: {"style":"default","highlight":"light","wordWrap":false},
  reward: false,
  fancybox: false,
  zoomImage: {"gapAside":"20px"},
  galleryWaterfall: undefined,
  lazyload: false,
  pjax: undefined,
  externalLink: {"icon":{"enable":true,"name":"fas fa-external-link-alt"}},
  shortcuts: undefined,
  prompt: {"copyButton":"复制","copySuccess":"复制成功","copyError":"复制失败"},
  sourcePath: {"js":"js","css":"css","images":"images"},
};

window.CONFIG = CONFIG;</script><meta name="generator" content="Hexo 5.4.0"></head><body><div class="container" id="container"><header class="header" id="header"><div class="header-inner"><nav class="header-nav header-nav--fixed"><div class="header-nav-inner"><div class="header-nav-menubtn"><i class="fas fa-bars"></i></div><div class="header-nav-menu"><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/"><span class="header-nav-menu-item__icon"><i class="fas fa-home"></i></span><span class="header-nav-menu-item__text">首页</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/about/"><span class="header-nav-menu-item__icon"><i class="fas fa-address-card"></i></span><span class="header-nav-menu-item__text">关于</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="javascript:;" onclick="return false;"><span class="header-nav-menu-item__icon"><i class="fas fa-edit"></i></span><span class="header-nav-menu-item__text">文章</span></a><div class="header-nav-submenu"><div class="header-nav-submenu-item"><a class="header-nav-submenu-item__link" href="/archives/"><span class="header-nav-submenu-item__icon"><i class="fas fa-folder-open"></i></span><span class="header-nav-submenu-item__text">归档</span></a></div><div class="header-nav-submenu-item"><a class="header-nav-submenu-item__link" href="/categories/"><span class="header-nav-submenu-item__icon"><i class="fas fa-layer-group"></i></span><span class="header-nav-submenu-item__text">分类</span></a></div><div class="header-nav-submenu-item"><a class="header-nav-submenu-item__link" href="/tags/"><span class="header-nav-submenu-item__icon"><i class="fas fa-tags"></i></span><span class="header-nav-submenu-item__text">标签</span></a></div></div></div></div><div class="header-nav-mode"><div class="mode"><div class="mode-track"><span class="mode-track-moon"></span><span class="mode-track-sun"></span></div><div class="mode-thumb"></div></div></div></div></nav><div class="header-banner"><div class="header-banner-info"><div class="header-banner-info__title">Strive's Blog</div><div class="header-banner-info__subtitle">You gotta conquer the monster in your head and then you'll fly.</div></div><div class="header-banner-arrow"><div class="header-banner-arrow__icon"><i class="fas fa-angle-down"></i></div></div></div></div></header><main class="main" id="main"><div class="main-inner"><div class="content-wrap" id="content-wrap"><div class="content content-home" id="content"><section class="postlist"><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2021/11/08/3060test/">3060test</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">发表于</span><span class="post-meta-item__value">2021-11-08</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">更新于</span><span class="post-meta-item__value">2021-11-08</span></span></div></header><div class="post-body"><div class="post-excerpt"><p>testtesttest</p>
</div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2021/11/02/labsever/">实验室服务器探索</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">发表于</span><span class="post-meta-item__value">2021-11-02</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">更新于</span><span class="post-meta-item__value">2021-11-02</span></span></div></header><div class="post-body"><div class="post-excerpt">
        <h3 id="前置准备：">
          <a href="#前置准备：" class="heading-link"><i class="fas fa-link"></i></a><a href="#前置准备：" class="headerlink" title="前置准备："></a>前置准备：</h3>
      <p>由于没找到便捷的传文件到服务器的方法，有时需要从自己电脑中粘贴代码到服务器的编译器上运行，可以在登录服务器之前点击显示选项在本地资源上点击剪贴板，这样自己电脑的代码就能复制粘贴到服务器编译器上了。</p>
<p><img src="/images/labsever/image-20211102104735926.png" alt="image-20211102104735926"></p>
<p><img src="/images/labsever/image-20211102104817924.png" alt="image-20211102104817924"></p>

        <h3 id="一、安装Anaconda">
          <a href="#一、安装Anaconda" class="heading-link"><i class="fas fa-link"></i></a><a href="#一、安装Anaconda" class="headerlink" title="一、安装Anaconda"></a>一、安装Anaconda</h3>
      <p>首先进入到具有Anaconda安装包的目录下，记得指令中的dxs是自己的用户名</p>
<p><code>cd /home/dxs/anaconda</code></p>
<p><img src="/images/labsever/image-20211101202849128.png" alt="image-20211101202849128"></p>
<p>输入命令： <code>bash Anaconda3-5.2.0-Linux-x86_64.sh</code></p>
<p>回车开始执行安装程序</p>
<p>出现许可协议后一直按回车到出现是否接受(yes/no)</p>
<p>一直输入yes直到出现最后一步有一个询问你是否安装vscode，emm如果你没有需要就输入no。</p>

        <h3 id="二、安装pycharm">
          <a href="#二、安装pycharm" class="heading-link"><i class="fas fa-link"></i></a><a href="#二、安装pycharm" class="headerlink" title="二、安装pycharm"></a>二、安装pycharm</h3>
      <p>首先进入到具有Anaconda安装包的目录下</p>
<p><code>cd home/dxs/anaconda</code>, 回车</p>
<p>输入ls查看pycharm文件夹的文件夹名<img src="/images/labsever/image-20211101205032654.png" alt="image-20211101205032654"></p>
<p>linux下的复制快捷键是<strong>ctrl+alt+c</strong></p>
<p>粘贴是<strong>ctrl+alt+v</strong></p>
<p>使用复制快捷键复制这个长文件夹名，输入cd 粘贴文件夹名/bin</p>
<p><code>cd pycharm-community-2020.2.2/bin</code></p>
<p>回车，如上图所示红线下面的命令</p>
<p>然后输入 <code>./pycharm.sh</code> 回车开始安装</p>
<p>然后会弹出对话框</p>
<p><img src="/images/labsever/image-20211101205511516.png" alt="image-20211101205511516"></p>
<p><img src="/images/labsever/image-20211101205539700.png" alt="image-20211101205539700"></p>
<p>选择界面风格</p>
<p><img src="/images/labsever/image-20211101205632388.png" alt="image-20211101205632388"></p>
<p>选一个好看的点击next</p>
<p>下一个界面不要选择创建直接下一步就完成了安装</p>

        <h4 id="下次怎么进入pycharm">
          <a href="#下次怎么进入pycharm" class="heading-link"><i class="fas fa-link"></i></a><a href="#下次怎么进入pycharm" class="headerlink" title="下次怎么进入pycharm"></a>下次怎么进入pycharm</h4>
      <p>先给它创建一个快捷方式，在桌面上右键选择create launcher</p>
<p><img src="/images/labsever/image-20211101211141456.png" alt="image-20211101211141456"></p>
<p>输入名字，点击command旁边的小文件夹，找到pycharm的bin文件夹找到pycharm.sh选中点击open</p>
<p><img src="/images/labsever/image-20211101211401520.png" alt="image-20211101211401520"></p>
<p>点击icon给它选择一个图标，search icon中选择image files，在弹出的选择目录中还在这个bin目录里面可以找到这个图标，选择点击ok就好啦</p>
<p><img src="/images/labsever/image-20211101211556431.png" alt="image-20211101211556431"></p>
<p><img src="/images/labsever/image-20211101211710022.png" alt="image-20211101211710022"></p>
<p><img src="/images/labsever/image-20211101211747217.png" alt="image-20211101211747217"></p>
<p>打上第一个勾点击create，桌面上就有pycharm了，双击打开点击launch anyway就打开了</p>
<p><img src="/images/labsever/image-20211101211825065.png" alt="image-20211101211825065"></p>
<p><img src="/images/labsever/image-20211101211905407.png" alt="image-20211101211905407"></p>

        <h3 id="三、pytorch环境搭建">
          <a href="#三、pytorch环境搭建" class="heading-link"><i class="fas fa-link"></i></a><a href="#三、pytorch环境搭建" class="headerlink" title="三、pytorch环境搭建"></a>三、pytorch环境搭建</h3>
      <p>右击桌面找到Applications-&gt;system-&gt;Xfce Terminal点击打开终端</p>
<p><img src="/images/labsever/image-20211102102926834.png" alt="image-20211102102926834"></p>
<p>1、进入conda环境，在终端中输入下面指令进入到创建好的torchgpu虚拟环境</p>
<figure class="highlight plaintext"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source activate torchgpu</span><br></pre></td></tr></table></div></figure>

<p>3、安装pytorch</p>
<p><img src="/images/labsever/image-20211101221521349.png" alt="image-20211101221521349"></p>
<p><code>conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch</code> 复制这行代码，回车开始安装</p>
<p>出现yes/no全部yes即可</p>
<p>4、安装李沐的d2l包，里面附带有jupyter，推荐安装</p>
<p><code>pip install d2l</code></p>
<p>至此pytorch需要的一些包和环境安装完毕</p>

        <h3 id="四、尝试使用jupyter编写代码">
          <a href="#四、尝试使用jupyter编写代码" class="heading-link"><i class="fas fa-link"></i></a><a href="#四、尝试使用jupyter编写代码" class="headerlink" title="四、尝试使用jupyter编写代码"></a>四、尝试使用jupyter编写代码</h3>
      <p>按照上面的方法打开终端并进入到torchgpu环境下，输入 <code>jupyter notebook</code>回车会弹出浏览器,即可使用jupyter编写代码</p>
<p><img src="/images/labsever/image-20211102104101453.png" alt="image-20211102104101453"></p>
<p><img src="/images/labsever/image-20211102104150415.png" alt="image-20211102104150415"></p>

        <h3 id="五、尝试使用pycharm编写代码">
          <a href="#五、尝试使用pycharm编写代码" class="heading-link"><i class="fas fa-link"></i></a><a href="#五、尝试使用pycharm编写代码" class="headerlink" title="五、尝试使用pycharm编写代码"></a>五、尝试使用pycharm编写代码</h3>
      <p>pycharm还是跟windows上一样设置环境为创建的conda虚拟环境torchgpu</p>
<p>点击file-&gt;settings-&gt;Project Interpreter-&gt;小齿轮按钮</p>
<p><img src="/images/labsever/image-20211102110238056.png" alt="image-20211102110238056"></p>
<p>conda environments-&gt;existing enviornment点击小文件夹按钮</p>
<p>依次找到路径 /home/dxs(自己的用户名)/anaconda3/envs/torchgpu/bin/python</p>
<p>点击ok apply</p>
<p>返回之后右下角出现（torchgpu）说明环境已经切换完毕</p>
<p><img src="/images/labsever/image-20211102110856616.png" alt="image-20211102110856616"></p>

        <h3 id="六、使用gpu之前的一些注意事项">
          <a href="#六、使用gpu之前的一些注意事项" class="heading-link"><i class="fas fa-link"></i></a><a href="#六、使用gpu之前的一些注意事项" class="headerlink" title="六、使用gpu之前的一些注意事项"></a>六、使用gpu之前的一些注意事项</h3>
      <p>使用gpu之前先打开终端输入 <code>nvidia-smi</code>查看显卡的使用状态</p>
<p><img src="/images/labsever/image-20211102111112560.png" alt="image-20211102111112560"></p>
<p>可以看到第一块显卡（GPU0）的显存使用很大，我们尽量选择较为空闲的显卡比如GPU7，以避免与师兄师姐争用显存，从GPU7显存使用2MiB可见较为空闲，因此在训练的代码中注意将训练设备设置成CUDA:7 即GPU7</p>
<p>原代码：</p>
<p><img src="/images/labsever/image-20211102111531575.png" alt="image-20211102111531575"></p>
<p>只使用GPU7的改正的代码：</p>
<p><img src="/images/labsever/image-20211102111612414.png" alt="image-20211102111612414"></p>
<p>到此，实验室服务器探索暂时告一段落，以后有需要会接着尝试。</p>
</div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2021/10/24/dalunwen/">《**基于深度学习跨模态行人再识别系统的研究与实现**》阅读</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">发表于</span><span class="post-meta-item__value">2021-10-24</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">更新于</span><span class="post-meta-item__value">2021-10-28</span></span></div></header><div class="post-body"><div class="post-excerpt">
        <h3 id="师兄大论文《基于深度学习跨模态行人再识别系统的研究与实现》阅读">
          <a href="#师兄大论文《基于深度学习跨模态行人再识别系统的研究与实现》阅读" class="heading-link"><i class="fas fa-link"></i></a><a href="#师兄大论文《基于深度学习跨模态行人再识别系统的研究与实现》阅读" class="headerlink" title="师兄大论文《基于深度学习跨模态行人再识别系统的研究与实现》阅读"></a>师兄大论文《<strong>基于深度学习跨模态行人再识别系统的研究与实现</strong>》阅读</h3>
      
        <h4 id="一、论文提出问题与名词解释">
          <a href="#一、论文提出问题与名词解释" class="heading-link"><i class="fas fa-link"></i></a><a href="#一、论文提出问题与名词解释" class="headerlink" title="一、论文提出问题与名词解释"></a>一、论文提出问题与名词解释</h4>
      
        <h5 id="1-1-行人再识别-Re-ID">
          <a href="#1-1-行人再识别-Re-ID" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-1-行人再识别-Re-ID" class="headerlink" title="1.1 行人再识别 Re-ID"></a>1.1 行人再识别 Re-ID</h5>
      <p>行人再识别的背景主要是判利用计算机视觉技术判断图像或者视频序列中是否存在特定的行人。其主要应当包括两个方面：行人检测与行人识别。</p>
<p>行人检测方面主要完成利用计算机视觉相关技术判断图像或视频序列中是否包含行人，如果包含行人则对每个行人标注独立的行人框，并将这些行人框裁剪提供给行人再识别系统进行身份识别。</p>
<p>行人再识别系统完成的功能是根据裁剪后输入的多个行人图片判断是否为同一行人。</p>

        <h5 id="1-2-跨模态行人再识别-IV-ReID">
          <a href="#1-2-跨模态行人再识别-IV-ReID" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-2-跨模态行人再识别-IV-ReID" class="headerlink" title="1.2 跨模态行人再识别 IV-ReID"></a>1.2 跨模态行人再识别 IV-ReID</h5>
      <p>当照明条件不佳的时候，RGB摄像头往往表现不佳，但是红外摄像头则可以良好工作。如果给定一个特定的人的可见（或红外图像），系统跨模态的从其他光谱相机中捕获的图库中搜索相应的红外（或可见光）图像可以实现更好的效果。这种交叉模态图像匹配任务称为跨模态行人再识别(IV-REID)</p>

        <h4 id="二、行人检测部分">
          <a href="#二、行人检测部分" class="heading-link"><i class="fas fa-link"></i></a><a href="#二、行人检测部分" class="headerlink" title="二、行人检测部分"></a>二、行人检测部分</h4>
      <p>对于行人检测部分，应当归类为目标检测问题。师兄采用的行人检测网络是anchor free检测网络中的CenterNet网络。</p>

        <h5 id="2-1-Anchor-free网络模型">
          <a href="#2-1-Anchor-free网络模型" class="heading-link"><i class="fas fa-link"></i></a><a href="#2-1-Anchor-free网络模型" class="headerlink" title="2.1 Anchor free网络模型"></a>2.1 Anchor free网络模型</h5>
      
        <h6 id="2-1-1-什么是Anchor">
          <a href="#2-1-1-什么是Anchor" class="heading-link"><i class="fas fa-link"></i></a><a href="#2-1-1-什么是Anchor" class="headerlink" title="2.1.1 什么是Anchor"></a>2.1.1 什么是Anchor</h6>
      <p>Anchor是在图像上预设好的不同大小，不同长宽比的参照框。借助神经网络强大的拟合能力，不需要再计算Haar/Hog等特征。网络直接输出每个anchor包含（或者说与物体有较大重叠，也就是IoU较大的）物体的概率，以及被检测物体相对于本Anchor的中心点偏移以及长宽比例。如下图</p>
<p><img src="/images/dalunwen/image-20211012094040232.png" alt="image-20211012094040232"></p>
<p>因为anchor的位置都是固定的，所以就可以很容易的换算出来实际物体的位置。以图中的小猫为例，红色的anchor就以99%的概率认为它是一只猫，并同时给出了猫的实际位置相对于该anchor的偏移量，这样，我们将输出解码后就得到了实际猫的位置，如果它能通过NMS（非最大抑制）筛选，它就能顺利的输出来。但是，绿色的anchor就认为它是猫的概率就很小，紫色的anchor虽然与猫有重叠，但是概率只有26%。在训练的时候，也就是给每张图片的物体的Bounding Box，相对于anchor进行编码，如果物体的Bounding Box与某个anchor的IoU较大，例如大于0.5就认为是正样本，否则是负样本（当然，也有算法将大于0.7的设为正样本，小于0.3的算负样本，中间的不计算损失）。</p>

        <h6 id="2-1-2-什么是IoU（Intersection-over-Union）">
          <a href="#2-1-2-什么是IoU（Intersection-over-Union）" class="heading-link"><i class="fas fa-link"></i></a><a href="#2-1-2-什么是IoU（Intersection-over-Union）" class="headerlink" title="2.1.2 什么是IoU（Intersection over Union）"></a>2.1.2 什么是IoU（Intersection over Union）</h6>
      <p>IoU是一种测量在特定数据集中检测相应物体准确度的一个标准。IoU是一个简单的测量标准，只要是在输出中得出一个预测范围(bounding boxex)的任务都可以用IoU来进行测量。为了可以使IoU用于测量任意大小形状的物体检测，我们需要：</p>
<ul>
<li><p>ground-truth bounding boxes（人为在训练集图像中标出要检测物体的大概范围）</p>
</li>
<li><p>我们的算法得出的结果范围。</p>
</li>
</ul>
<p><strong>这个标准用于测量真实和预测之间的相关度，相关度越高该值越高。</strong>其<strong>计算方法是两个区域重叠的部分除以两个区域的集合部分得出的结果</strong>，通过设定的IoU阈值，与IoU计算结果进行比较。如图2所示：</p>
<img src="/images/dalunwen/image-20211012202618543.png" alt="image-20211012202618543" style="zoom:50%;">

<p>​                                                                                                                        图2 IoU的计算公式</p>
<img src="/images/dalunwen/image-20211012202816848.png" alt="image-20211012202816848" style="zoom:75%;">


        <h6 id="2-1-3-CenterNet">
          <a href="#2-1-3-CenterNet" class="heading-link"><i class="fas fa-link"></i></a><a href="#2-1-3-CenterNet" class="headerlink" title="2.1.3 CenterNet"></a>2.1.3 CenterNet</h6>
      <p>CenterNet正是Anchor Free的网络模型。CenterNet 首次提出了运用关键点检测算法确定目标中心点。<strong>CenterNet的基本思想是在确定目标中心点的前提下预测目标的宽高。</strong>CenterNet采用了关键点检测的方法，对特征的每个区域取8邻域最大值作为极值点，然后保留100个极值点，作为目标框的中心点，并且通过设置一定的阈值滤除低质量的目标中心点。CenterNet的网络框架如图所示：</p>
<p><img src="/images/dalunwen/image-20211014212357048.png" alt="image-20211014212357048"></p>

        <h5 id="2-2-本论文对CenterNet的改进">
          <a href="#2-2-本论文对CenterNet的改进" class="heading-link"><i class="fas fa-link"></i></a><a href="#2-2-本论文对CenterNet的改进" class="headerlink" title="2.2 本论文对CenterNet的改进"></a>2.2 本论文对CenterNet的改进</h5>
      <p>论文提出了两个对CenterNet的改进方向。由于CenterNet的基本思路是先利用预测中心点算法预测目标中心点，再在中心点的基础上预测宽高。出现检测不准的情况可能是1、网络未预测正确的目标中心点，后面宽高预测分支即使十分精准也会出现误检框，2、目标中心点预测精准但是而宽高预测分支未输出正确的宽高，那么也会造成误检框。并为此改进了网络的结构与损失函数。</p>

        <h6 id="2-2-1-网络结构的改进">
          <a href="#2-2-1-网络结构的改进" class="heading-link"><i class="fas fa-link"></i></a><a href="#2-2-1-网络结构的改进" class="headerlink" title="2.2.1 网络结构的改进"></a>2.2.1 网络结构的改进</h6>
      <p>对于中心预测分支主要采取的方法是提取特征图8-临域内最大值作为目标的中心点。由于有时会出现极值点并不是目标的中心点的情况，师兄在上图的原有CenterNet的结构中加入了注意力网络中的全局上下文模块（Global Context Block）。</p>
<p>注意力网络可以使局部区域加权后特征值变大，我们利用此特性进行训练并约束网络，使训练图片的目标中心点分配较高的权重，非目标中心点分配较低的权重，使特征图的极值点均为目标中心点，避免产生中心点误检的情况。</p>

        <h6 id="2-2-2-损失函数改进">
          <a href="#2-2-2-损失函数改进" class="heading-link"><i class="fas fa-link"></i></a><a href="#2-2-2-损失函数改进" class="headerlink" title="2.2.2 损失函数改进"></a>2.2.2 损失函数改进</h6>
      <p>CenterNet的预测分支的损失函数是Smooth L1 loss，原理是对检测框进行宽高的回归优化，但是没有将检测框视作一个整体进行优化，导致检测网络的精度较低。</p>
<p>CIOU loss，此损失函数兼顾了预测框与真实框的相交程度、欧式距离、长宽比等多个因素，且较为容易收敛，旨在使预测框更加符合真实框,其公式为：<img src="/images/dalunwen/image-20211024143007780.png" alt="image-20211024143007780">。</p>
<p>其中，<img src="/images/dalunwen/image-20211024143042745.png" alt="image-20211024143042745" style="zoom:65%;">表示预测框与真实框中心点的欧式距离，c表示预测框和真实框的最小外接矩形的对角线距离。<img src="/images/dalunwen/image-20211024143117350.png" alt="image-20211024143117350" style="zoom:67%;">表示真实框与目标框长宽比的距离。</p>

        <h4 id="三、跨模态行人再识别部分">
          <a href="#三、跨模态行人再识别部分" class="heading-link"><i class="fas fa-link"></i></a><a href="#三、跨模态行人再识别部分" class="headerlink" title="三、跨模态行人再识别部分"></a>三、跨模态行人再识别部分</h4>
      
        <h5 id="3-1-评估指标">
          <a href="#3-1-评估指标" class="heading-link"><i class="fas fa-link"></i></a><a href="#3-1-评估指标" class="headerlink" title="3.1 评估指标"></a>3.1 评估指标</h5>
      
        <h6 id="3-1-1-CMC曲线">
          <a href="#3-1-1-CMC曲线" class="heading-link"><i class="fas fa-link"></i></a><a href="#3-1-1-CMC曲线" class="headerlink" title="3.1.1 CMC曲线"></a>3.1.1 CMC曲线</h6>
      <p>CMC曲线全称为累计匹配曲线，是图像检索领域的重要检测指标。在行人再识别测试时，分别输入查询目标库的图片（query）和候选库图片（gallery），计算查询库中每一个行人与候选库中的每一个行人的相似度，并根据相似度进行排序，相似度列表由一个二维矩阵表示。相似度列表的横坐标为n，表示相似度排名，纵坐标为Rank_n，表示排序靠前的行人与目标行人具有相同ID的概率，例如，某个模型进行测试，取排序前十的图片进行分析，前十中共有5张正确图片被召回，这5张正确图片的排序下标为1，2，5，7，8，那么该模型的rank_1为100%，rank_5为60%，rank_10为50%。因此，可以根据此指标来判断模型的分类能力。</p>

        <h6 id="3-1-2-mAP-平均检索精度">
          <a href="#3-1-2-mAP-平均检索精度" class="heading-link"><i class="fas fa-link"></i></a><a href="#3-1-2-mAP-平均检索精度" class="headerlink" title="3.1.2 mAP 平均检索精度"></a>3.1.2 mAP 平均检索精度</h6>
      <p>当gallery图库中出现大量的同一个行人的图片时，被召回率会大大提高，在rank机制下，误判的图片几乎不起作用，此时Rank就不能很好地判断模型的好坏，于是研究人员提出使用平均检索精度（mAP）来评估算法的优劣。mAP为查询目标库中所有图片的检索精度的平均值，即query中所有图片查准率的平均值。例如，有两个模型验证性能的好坏，我们进行测试，第一个模型有4个正确图片被召回，第二个模型也有4个正确图片被召回，第一个模型被召回的正确图片排序下标为1，2，3，5，第二个模型被召回的正确图片排序下标为1，3，5，6。那么第一个模型的平均准确率为（1/1+2/2+3/3+4/5）/4=0.95，第二个模型的平均准确率为（1/1+2/3+3/5+4/6）/4=0.75，从上述计算可以看出第一个模型效果更好，因此，此指标有力的弥补了Rank指标的缺陷。</p>

        <h5 id="3-2-跨模态行人再识别算法的思路">
          <a href="#3-2-跨模态行人再识别算法的思路" class="heading-link"><i class="fas fa-link"></i></a><a href="#3-2-跨模态行人再识别算法的思路" class="headerlink" title="3.2 跨模态行人再识别算法的思路"></a>3.2 跨模态行人再识别算法的思路</h5>
      <p>跨模态行人再识别主要是使用RGB图片与红外图片做跨模态学习。RGB图片通常具有较高的空间分辨率和可观的细节和明暗对比，因此，它们适合于人类的视觉感知。然而，这些图像很容易受到恶劣条件的影响，如光照差、雾和恶劣天气。但是，描述物体热辐射的红外图像具有一定抗干扰的能力，但其通常分辨率较低，纹理较差。因此，红外图片与RGB图片所具有的共性集中在纹理、轮廓、图案等外观信息，比如同一个行人穿有一件带有logo图案的衣服，那么不管是他的红外图片还是他的RGB图片都会有显眼的logo图案，且图案纹理轮廓相似度极大。</p>
<p>神经网络的较浅层提取的特征主要关注图像的纹理颜色等外观细节，而提取的深层特征则包含语义信息。我们认为红外图片和可见光图片的低层次的外观特征具有更高相似性，所以学习低层次特征能够得到更具有可辨性的共性特征。</p>

        <h5 id="3-3-具体算法框架">
          <a href="#3-3-具体算法框架" class="heading-link"><i class="fas fa-link"></i></a><a href="#3-3-具体算法框架" class="headerlink" title="3.3 具体算法框架"></a>3.3 具体算法框架</h5>
      <p><img src="/images/dalunwen/image-20211024190307293.png" alt="image-20211024190307293"></p>
<p>网络架构是采用常用的跨模态网络结构——双流网络，模型的骨干网络是ResNet-50，以前的方法只采用最深层的特征来编码图片，例如来自ResNet-50最后一个卷积层的输出。最后一个卷积层输出的是深层特征，即有关于图片的语义信息。尽管高级特征对于形成抽象概念用于物体识别确实有用，但它们可能会丢弃颜色和纹理等低级信号，这些信息是人物识别的重要线索。此外，卷积神经网络深层特征的分辨率较小，可能无法看到细节，如衣服上的图案，面部特征，细微的姿势差异等。这表明提取多层次特征，并且利用多层次特征的信息优势互补有利于行人重识别任务。</p>

        <h6 id="3-3-1-特征提取">
          <a href="#3-3-1-特征提取" class="heading-link"><i class="fas fa-link"></i></a><a href="#3-3-1-特征提取" class="headerlink" title="3.3.1 特征提取"></a>3.3.1 特征提取</h6>
      <p>如上文所述，师兄认为深层特征会忽略图片的一些纹理细节，而这些细节对于身份识别是有帮助的。因此师兄分别提取RGB图像、红外图像在ResNet-50的block_2、block_3、block_4层的输出作为浅层特征、中层特征、深层特征，分别用X1、X2、X3、X4、X5、X6表示。然后分别对两种图片的浅层、中层、深层特征表示做向量拼接作为特征融合。融合后的特征分别用B1、B2、B3表示。公式如下。</p>
<p><img src="/images/dalunwen/image-20211024204302667.png" alt="image-20211024204302667"></p>
<p>concatenate表示向量拼接，相比特征直接相加，其主要优势是特征融合前后特征维度不变，保证信息不会丢失，X1、X4表示RGB图片和红外图片的浅层特征，X2、X5表示RGB图片和红外图片的中层特征，X3、X6表示RGB图片和红外图片的深层特征，0表示在batch维度上进行拼接，即RGB特征和红外特征进行融合，消除模态差异。</p>

        <h6 id="3-3-2-特征分割">
          <a href="#3-3-2-特征分割" class="heading-link"><i class="fas fa-link"></i></a><a href="#3-3-2-特征分割" class="headerlink" title="3.3.2 特征分割"></a>3.3.2 特征分割</h6>
      <p><strong>将图像特征分割成不同的局部特征能够显著提高行人再识别的准确性。其次，全局特征能够捕捉最显著的外观特征，而局部特征可以捕捉图像的细节</strong>，将图像特征分成局部特征和全局特征已经得到广泛的应用。由于<strong>低层特征分辨率更高，包含更多位置、细节信息，但是由于经过的卷积更少，其语义性更低，噪声更多，而高层特征具有更强的语义信息，但是分辨率很低，对细节的感知能力较差，中层特征介于两者之间。</strong>因此对高层层和中层特征X3,X2做特征分割。对于X1不分割，对于X2分割为两个局部特征，对于X3分割为三个局部特征，这样分割更加符合人体结构构造，例如上半身，下半身（或头、上半身、下半身）。且通过实验结果表明，这种分割的方法达到的效果最好。其公式如下，</p>
<p><img src="/images/dalunwen/image-20211024211727622.png" alt="image-20211024211727622"></p>
<p>P1、P2为中层特征的局部特征，P3、P4、P5为深层特征的局部特征。同时将低层次特征、中层次特征和高层次特征的全局特征保留，其公式如下，</p>
<p><img src="/images/dalunwen/image-20211024211859494.png" alt="image-20211024211859494"></p>
<p>正如之前写的卷积神经网络那篇博文，池化操作的<strong>首要作用是降采样汇合结果中的一个元素对应于原输入数据的一个子区域（sub-region），因此汇合相当于在空间范围内做了维度约减（spatially dimension reduction），从而使模型可以抽取更广范围的特征。同时减小了下一层输入大小，进而减小计算量和参数个数。</strong>其次池化操作还具有<strong>降维、去除冗余信息、对特征进行压缩、简化网络复杂度、减小计算量、减小内存消耗等等。</strong>因此对B1,B2,B3做池化操作提取出三个层次的全局特征G1,G2,G3。</p>
<p>同时，对分割出的局部特征P1-P5作降维操作得到局部特征。旨在减少运算量并滤除冗余信息，其公式如下，</p>
<p><img src="/images/dalunwen/image-20211024212619478.png" alt="image-20211024212619478"></p>
<p>其中，R1、R2、R3、R4、R5表示三个层次的局部特征，即分割后的特征在通道维度上降维为256得到局部特征。</p>

        <h6 id="3-3-3-对于全局特征的损失函数">
          <a href="#3-3-3-对于全局特征的损失函数" class="heading-link"><i class="fas fa-link"></i></a><a href="#3-3-3-对于全局特征的损失函数" class="headerlink" title="3.3.3 对于全局特征的损失函数"></a>3.3.3 对于全局特征的损失函数</h6>
      <p>对于全局特征求两个损失函数，分别是用于度量学习的三元组损失（Triplet loss）和用于分类的交叉熵损失（Softmax loss）。对于全局特征B1、B2、B3采用交叉熵损失函数和三元组损失函数联合优化，其公式如下，</p>
<p><img src="/images/dalunwen/image-20211024212738320.png" alt="image-20211024212738320"></p>
<p>其中，L1、L3、L7表示三个层次的全局特征的三元组损失，L2、L4、L8表示三个层次的全局特征的交叉熵损失。</p>

        <h6 id="3-3-4-对于局部特征的损失函数">
          <a href="#3-3-4-对于局部特征的损失函数" class="heading-link"><i class="fas fa-link"></i></a><a href="#3-3-4-对于局部特征的损失函数" class="headerlink" title="3.3.4 对于局部特征的损失函数"></a>3.3.4 对于局部特征的损失函数</h6>
      <p>对于局部特征仅仅采用交叉熵损失函数进行优化，原因是<strong>局部特征可能会出现特征未对齐问题，导致局部特征可能存在巨大变化，因此，三元组损失在训练期间可能会破坏模型优化。</strong>其公式如下，</p>
<p><img src="/images/dalunwen/image-20211024212909969.png" alt="image-20211024212909969"></p>
<p>其中，L5、L6表示中层局部特征的交叉熵损失，L9、L10、L11表示深层局部特征的交叉熵损失。</p>

        <h6 id="3-3-5-总损失函数">
          <a href="#3-3-5-总损失函数" class="heading-link"><i class="fas fa-link"></i></a><a href="#3-3-5-总损失函数" class="headerlink" title="3.3.5 总损失函数"></a>3.3.5 总损失函数</h6>
      <p>由于学习低层次特征可以获得更多的跨模态共性特征，所以我们提取了网络中的多层次特征。然而，我们发现<strong>不同任务损失的尺度差异非常大，如果采取简单相加的方式，整体损失函数将不会是最佳的，导致网络模型得不到充分的优化</strong>。</p>
<p>因此，我们采用多任务学习的方法，结合多个损失函数，利用同<strong>方差不确定性</strong>同时学习多个目标。我们将同方差不确定性解释为依赖于任务的加权。我们<strong>设置了三个可学习的超参数，分别集成到每个任务的损失中，三个噪声参数分别作为低层特征、中层特征和高层特征损失的权重因子。然后，将所有经过适当加权的损失相加，得到最优的总损失，从而达到对不同层次特征进行优化的目的</strong>。因此，我们最终的总损失函数为:</p>
<p><img src="/images/dalunwen/image-20211024213329932.png" alt="image-20211024213329932"></p>

        <h4 id="四-结论">
          <a href="#四-结论" class="heading-link"><i class="fas fa-link"></i></a><a href="#四-结论" class="headerlink" title="四 结论"></a>四 结论</h4>
      <p>师兄分别在行人再识别的两个部分进行改进，在行人检测部分对网络结构进行改进，在CenterNet的基础上加入了注意力模块，提升了预测目标中心点的精度。在损失函数部分将CenterNet的损失函数改进为CIOU，将检测框视作一个整体进行优化。</p>
<p>在行人识别部分使用了跨模态的学习方法。采用了以ResNet-50为主干网络的双流网络去分别提取RGB图像与红外图像的低、中、高层特征。并采取向量拼接作为特征融合消除模态间差异。并采取特征分割将特征分为全局特征与局部特征。全局特征的提取方法是分别对特征融合后的低中高层特征作最大值池化操作。为了更好的提取细节特征，对中层与高层特征作特征分割之后将分割后的深层特征降维处理滤除冗余信息得到局部特征。并分别对局部特征与全局特征提出了对应的损失函数。最终取得了较好的效果</p>
</div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2021/10/20/LeNet/">传统网络实现之LeNet</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">发表于</span><span class="post-meta-item__value">2021-10-20</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">更新于</span><span class="post-meta-item__value">2021-10-22</span></span></div></header><div class="post-body"><div class="post-excerpt">
        <h3 id="传统网络实现之LeNet">
          <a href="#传统网络实现之LeNet" class="heading-link"><i class="fas fa-link"></i></a><a href="#传统网络实现之LeNet" class="headerlink" title="传统网络实现之LeNet"></a>传统网络实现之LeNet</h3>
      
        <h4 id="LeNet简介">
          <a href="#LeNet简介" class="heading-link"><i class="fas fa-link"></i></a><a href="#LeNet简介" class="headerlink" title="LeNet简介"></a>LeNet简介</h4>
      <p>LeNet，它是最早发布的卷积神经网络之一，因其在计算机视觉任务中的高效性能而受到广泛关注。 这个模型是由 AT&amp;T 贝尔实验室的研究员 Yann LeCun 在1989年提出的（并以其命名），目的是识别图像中的手写数字。 当时，Yann LeCun 发表了第一篇通过反向传播成功训练卷积神经网络的研究，这项工作代表了十多年来神经网络研究开发的成果。</p>

        <h4 id="1-网络结构">
          <a href="#1-网络结构" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-网络结构" class="headerlink" title="1 网络结构"></a>1 网络结构</h4>
      <p>LeNet-5的网络结构如下图所示，由结构图可知LeNet是一个较为简单的神经网络，它包含了深度学习的基本模块如卷积层、池化层、全连接层等等。</p>
<img src="/images/LeNet/image-20211020191956320.png" alt="image-20211020191956320" style="zoom:50%;">

<p>​                                图1 LeNet-5的简化版示意图</p>
<p>LeNet的每个卷积块的基本单元是一个卷积层、一个sigmod激活函数和一个平均池化层。每个卷积层使用5×5的卷积核和一个sigmoid激活函数。</p>
<p>本次实验使用的数据集仍然是Fashion-mnist数据集，输入大小为28×28的图片。</p>

        <h4 id="2-代码实现">
          <a href="#2-代码实现" class="heading-link"><i class="fas fa-link"></i></a><a href="#2-代码实现" class="headerlink" title="2 代码实现"></a>2 代码实现</h4>
      
        <h5 id="2-1-使用到的库">
          <a href="#2-1-使用到的库" class="heading-link"><i class="fas fa-link"></i></a><a href="#2-1-使用到的库" class="headerlink" title="2.1 使用到的库"></a>2.1 使用到的库</h5>
      <p>`</p>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.utils <span class="keyword">import</span> data</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br></pre></td></tr></table></div></figure>

<p>`</p>

        <h5 id="2-2-定义网络结构">
          <a href="#2-2-定义网络结构" class="heading-link"><i class="fas fa-link"></i></a><a href="#2-2-定义网络结构" class="headerlink" title="2.2 定义网络结构"></a>2.2 定义网络结构</h5>
      <p>为了避免错误输入尺寸不是28×28的图片，因此定义的输入层应当具有将数据resize成28×28的格式的功能。</p>
<p>`</p>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义reshape层，实现的功能为继承Module类，将输入reshape成单通道28*28的黑白图片，第一维是数据的批量大小</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Reshape</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> x.view(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># LeNet</span></span><br><span class="line">net = nn.Sequential(</span><br><span class="line">    Reshape(),</span><br><span class="line">    nn.Conv2d(<span class="number">1</span>, <span class="number">6</span>, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>), nn.Sigmoid(), <span class="comment"># &quot;(28+4-5+1)=28&quot; 公式中的ph实际上是2倍的padding值</span></span><br><span class="line">    <span class="comment"># 因为torch分别在上下左右都加上padding值</span></span><br><span class="line">    nn.AvgPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>),  <span class="comment"># (28+2-2)/2=14</span></span><br><span class="line">    nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, kernel_size=<span class="number">5</span>), nn.Sigmoid(),  <span class="comment"># (14-5+1)=10</span></span><br><span class="line">    nn.AvgPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>),  <span class="comment"># (10+2-2)/2=5</span></span><br><span class="line">    nn.Flatten(),</span><br><span class="line">    nn.Linear(<span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>, <span class="number">120</span>), nn.Sigmoid(),</span><br><span class="line">    nn.Linear(<span class="number">120</span>, <span class="number">84</span>), nn.Sigmoid(),</span><br><span class="line">    nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></div></figure>

<p>`</p>

        <h5 id="2-3-工具函数类">
          <a href="#2-3-工具函数类" class="heading-link"><i class="fas fa-link"></i></a><a href="#2-3-工具函数类" class="headerlink" title="2.3 工具函数类"></a>2.3 工具函数类</h5>
      <p>定义在SoftMax那章的工具函数类，实现的功能是创建一个Accumulator类，Accumulator类创建的对象有着data属性，它是一个长度为n的列表，可以调用add（）函数实现data列表对应下标累加。在本代码中作用为创建一个Accumulator(3)对象，该列表的两个下标分别保存训练集总损失、训练集预测正确的总数与全部标签的数量，这样就可以利用前两个除以第三个来计算平均loss与预测正确率。</p>
<p>`</p>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Accumulator</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, n</span>):</span></span><br><span class="line">        self.data = [<span class="number">0.0</span>] * n</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add</span>(<span class="params">self, *args</span>):</span></span><br><span class="line">        self.data = [a + <span class="built_in">float</span>(b) <span class="keyword">for</span> a, b <span class="keyword">in</span> <span class="built_in">zip</span>(self.data, args)]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reset</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.data = [<span class="number">0.0</span>] * <span class="built_in">len</span>(self.data)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, idx</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.data[idx]</span><br></pre></td></tr></table></div></figure>

<p>`</p>
<p>定义两个计算准确率的函数</p>
<p><code>accuracy(y_hat, y)</code>函数实现的功能是统计一批输出的预测的数量。实现的功能是对一个batch_size个数据做预测，输出的y_hat是batch_size个10分类one_hot编码，对它做行方向上的argmax可以得到类别，如[0,0,1,0,0,0,0,0,0,0]作argmax得到预测的类别是第2类。y是标签数据，标注编号描述0T-shirt/top（T恤）1Trouser（裤子）2Pullover（套衫）3Dress（裙子）4Coat（外套）5Sandal（凉鞋）6Shirt（汗衫）7Sneaker（运动鞋）8Bag（包）9Ankle boot（踝靴）。cmp是一个保存y和y_hat相等结果布尔值的tensor，对这个tensor做sum（）可以得到预测正确的数量。</p>
<p>`</p>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">accuracy</span>(<span class="params">y_hat, y</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;y_hat为一批预测的张量，为batch_size个长度为10的one_hot编码&quot;&quot;&quot;</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;对one_hot编码在行（axis0为这批预测的数量）上做argmax得出预测的类别，y为batch_size个实数标签&quot;&quot;&quot;</span></span><br><span class="line">    y_hat = y_hat.argmax(axis=<span class="number">1</span>)</span><br><span class="line">    cmp = y_hat.<span class="built_in">type</span>(y.dtype) == y <span class="comment"># argmax之后的y_hat是一个0-9的实数，与y作比较，相同的</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">float</span>(cmp.<span class="built_in">type</span>(y.dtype).<span class="built_in">sum</span>())</span><br></pre></td></tr></table></div></figure>

<p>`</p>
<p><code>evaluate_accuracy(net, data_iter)</code>函数实现的功能是评估网络在测试集上的准确率。创建一个长度为2的Accumulator()对象，它的data第一个元素保存预测正确的数量，第二个利用y.numel()得到预测的总数并累加到第二个元素，最后利用第一个元素÷第二个元素的到正确率。</p>
<p>`</p>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate_accuracy</span>(<span class="params">net, data_iter</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(net, nn.Module):</span><br><span class="line">        net.<span class="built_in">eval</span>()</span><br><span class="line">    metric = Accumulator(<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">for</span> X, y <span class="keyword">in</span> data_iter:</span><br><span class="line">        metric.add(accuracy(net(X), y), y.numel())</span><br><span class="line">    <span class="keyword">return</span> metric[<span class="number">0</span>]/metric[<span class="number">1</span>]</span><br></pre></td></tr></table></div></figure>

<p>`</p>

        <h5 id="2-4-初始化网络参数与优化器">
          <a href="#2-4-初始化网络参数与优化器" class="heading-link"><i class="fas fa-link"></i></a><a href="#2-4-初始化网络参数与优化器" class="headerlink" title="2.4 初始化网络参数与优化器"></a>2.4 初始化网络参数与优化器</h5>
      <p>对线性层和卷积层的参数做Xavier初始化，采用随机梯度下降SGD算法作为优化器，并采用交叉熵损失作为损失函数。</p>
<p>`</p>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 初始化网络参数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">init_weights</span>(<span class="params">m</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">type</span>(m) == nn.Linear <span class="keyword">or</span> <span class="built_in">type</span>(m) == nn.Conv2d:</span><br><span class="line">        nn.init.xavier_uniform_(m.weight)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">lr, num_epochs = <span class="number">0.1</span>, <span class="number">10</span></span><br><span class="line">net.apply(init_weights)</span><br><span class="line">optimizer = torch.optim.SGD(net.parameters(), lr=lr)</span><br><span class="line">loss = nn.CrossEntropyLoss()</span><br></pre></td></tr></table></div></figure>

<p>`</p>

        <h5 id="2-5-训练函数">
          <a href="#2-5-训练函数" class="heading-link"><i class="fas fa-link"></i></a><a href="#2-5-训练函数" class="headerlink" title="2.5 训练函数"></a>2.5 训练函数</h5>
      <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_eopch</span>(<span class="params">net, train_iter, loss, updater</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(net, nn.Module):</span><br><span class="line">        net.train()</span><br><span class="line">    metric = Accumulator(<span class="number">3</span>)</span><br><span class="line">    <span class="keyword">for</span> X, y <span class="keyword">in</span> train_iter:</span><br><span class="line">        y_hat = net(X)</span><br><span class="line">        l = loss(y_hat, y)</span><br><span class="line">        updater.zero_grad()</span><br><span class="line">        l.backward()</span><br><span class="line">        updater.step()</span><br><span class="line">        metric.add(l, accuracy(y_hat, y), y.numel())</span><br><span class="line">    <span class="keyword">return</span> metric[<span class="number">0</span>] / metric[<span class="number">2</span>], metric[<span class="number">1</span>] / metric[<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">net, updater, loss, train_iter, test_iter, num_epoch</span>):</span></span><br><span class="line">    <span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">        <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epoch):</span><br><span class="line">            train_metrics = train_eopch(net, train_iter, loss, updater)</span><br><span class="line">            test_acc = evaluate_accuracy(net, test_iter)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;epoch:<span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>,训练集损失:<span class="subst">&#123;train_metrics[<span class="number">0</span>]&#125;</span>,训练集准确率:<span class="subst">&#123;train_metrics[<span class="number">1</span>]&#125;</span>,测试集准确率:<span class="subst">&#123;test_acc&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">num_epochs = <span class="number">20</span></span><br><span class="line">train(net, optimizer, loss, train_iter, test_iter, num_epochs)</span><br></pre></td></tr></table></div></figure>




        <h4 id="3-结果展示">
          <a href="#3-结果展示" class="heading-link"><i class="fas fa-link"></i></a><a href="#3-结果展示" class="headerlink" title="3 结果展示"></a>3 结果展示</h4>
      
        <h5 id="原网络的数据比较">
          <a href="#原网络的数据比较" class="heading-link"><i class="fas fa-link"></i></a><a href="#原网络的数据比较" class="headerlink" title="原网络的数据比较"></a>原网络的数据比较</h5>
      <p>原网络使用了Sigmoid激活函数与平均值池化，20轮epoch，学习率采用0.9，可以见到最终的测试集准确率来到了0.845左右，相较于softmax似乎提升不大</p>
<p><img src="/images/LeNet/image-20211020192838633.png" alt="image-20211020192838633"></p>

        <h5 id="将平均池化改成最大值池化，其他不变，上涨了一点">
          <a href="#将平均池化改成最大值池化，其他不变，上涨了一点" class="heading-link"><i class="fas fa-link"></i></a><a href="#将平均池化改成最大值池化，其他不变，上涨了一点" class="headerlink" title="将平均池化改成最大值池化，其他不变，上涨了一点"></a>将平均池化改成最大值池化，其他不变，上涨了一点</h5>
      <p><img src="/images/LeNet/image-20211020195102120.png" alt="image-20211020195102120"></p>

        <h5 id="保持学习率0-9不变，采取最大值池化-ReLU激活函数，出现了损失很大完全不降低，测试集准确率一直很低的情况">
          <a href="#保持学习率0-9不变，采取最大值池化-ReLU激活函数，出现了损失很大完全不降低，测试集准确率一直很低的情况" class="heading-link"><i class="fas fa-link"></i></a><a href="#保持学习率0-9不变，采取最大值池化-ReLU激活函数，出现了损失很大完全不降低，测试集准确率一直很低的情况" class="headerlink" title="保持学习率0.9不变，采取最大值池化+ReLU激活函数，出现了损失很大完全不降低，测试集准确率一直很低的情况"></a>保持学习率0.9不变，采取最大值池化+ReLU激活函数，出现了损失很大完全不降低，测试集准确率一直很低的情况</h5>
      <p><img src="/images/LeNet/image-20211022205227138.png" alt="image-20211022205227138"></p>
<p>百度了相关资料，推测可能是学习率过大且ReLU函数对学习率敏感，较大的学习率可能出现较大的梯度，较大梯度冲击导致神经元死亡。</p>

        <h5 id="尝试降低学习率至0-3">
          <a href="#尝试降低学习率至0-3" class="heading-link"><i class="fas fa-link"></i></a><a href="#尝试降低学习率至0-3" class="headerlink" title="尝试降低学习率至0.3"></a>尝试降低学习率至0.3</h5>
      <p><img src="/images/LeNet/image-20211022210608129.png" alt="image-20211022210608129"></p>
<p>达到了最好成绩约0.89</p>

        <h4 id="4-总结">
          <a href="#4-总结" class="heading-link"><i class="fas fa-link"></i></a><a href="#4-总结" class="headerlink" title="4 总结"></a>4 总结</h4>
      <p>LeNet作为较早的卷积神经网络模型，比起只采用一层softmax的方法有了一定的提升。接下来可以尝试采取更深层的网络模型进一步提升精度。</p>
</div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2021/10/17/week%20summary002/">每周计划与总结002</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">发表于</span><span class="post-meta-item__value">2021-10-17</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">更新于</span><span class="post-meta-item__value">2021-10-17</span></span></div></header><div class="post-body"><div class="post-excerpt">
        <h4 id="上周总结">
          <a href="#上周总结" class="heading-link"><i class="fas fa-link"></i></a><a href="#上周总结" class="headerlink" title="上周总结"></a>上周总结</h4>
      <p>十月直接摆烂，现在时间是2021年10月17日晚上8点59分，傻逼RNG直接跟我一起摆烂。。。。。。</p>
<p><img src="/images/week%20summary001/image-20211009160317243.png" alt="image-20211009160317243"></p>
<p>除了基本上看完了动手学深度学习的第六章，其他的啥也没干。理由找是肯定能找，但其实并不是什么借口，<del>下周一定不摆烂，少打原神少看TMD RNG</del>。</p>

        <h4 id="下周（10-18-10-24）计划">
          <a href="#下周（10-18-10-24）计划" class="heading-link"><i class="fas fa-link"></i></a><a href="#下周（10-18-10-24）计划" class="headerlink" title="下周（10.18-10.24）计划"></a>下周（10.18-10.24）计划</h4>
      <ul>
<li><p>《动手学深度学习》第七章实现到VGG（需要学习checkpoints的使用和尝试使用Colab），看沐神的精读论文第一和第二个视频，读AlexNet那篇论文（中特课）</p>
</li>
<li><p>至少把师兄的大论文读完，并把读论文笔记写完</p>
</li>
<li><p>六级试卷*1（还有tm不到两个月能不能别裸考）</p>
</li>
<li><p>《算法导论》1-3章（周一上午读两章）</p>
</li>
<li><p>《c++ Primer》3-4章</p>
</li>
<li><p>矩阵论、数理统计复习</p>
</li>
</ul>
<p>下周再摆烂直接tm抽自己。</p>
<p><img src="/images/week%20summary001/image-20211009160233635.png" alt="image-20211009160233635"></p>
</div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2021/10/11/Convolutional%20Neural%20Networks/">卷积神经网络</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">发表于</span><span class="post-meta-item__value">2021-10-11</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">更新于</span><span class="post-meta-item__value">2021-10-29</span></span></div></header><div class="post-body"><div class="post-excerpt">
        <h3 id="第六章-卷积神经网络">
          <a href="#第六章-卷积神经网络" class="heading-link"><i class="fas fa-link"></i></a><a href="#第六章-卷积神经网络" class="headerlink" title="第六章 卷积神经网络"></a>第六章 卷积神经网络</h3>
      
        <h4 id="一、适合计算机视觉的模型应有特性">
          <a href="#一、适合计算机视觉的模型应有特性" class="heading-link"><i class="fas fa-link"></i></a><a href="#一、适合计算机视觉的模型应有特性" class="headerlink" title="一、适合计算机视觉的模型应有特性"></a>一、适合计算机视觉的模型应有特性</h4>
      <p>不变性是对于处理图像来说非常好的特性。不变性是指目标的外观发生了某种变化，即图像中目标无论是被平移，被旋转，还是被缩放，甚至是不同的光照条件、视角，训练的模型仍然应该将其正确识别。</p>
<p>具体来说，不变性包括：</p>
<ul>
<li>平移不变性：Translation Invariance</li>
<li>旋转/视角不变性：Ratation/Viewpoint Invariance</li>
<li>尺度不变性：Size Invariance</li>
<li>光照不变性：Illumination Invariance</li>
</ul>

        <h5 id="1-1-平移不变性">
          <a href="#1-1-平移不变性" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-1-平移不变性" class="headerlink" title="1.1 平移不变性"></a>1.1 平移不变性</h5>
      <p>在欧几里得几何中，平移是一种几何变换，表示把一幅图像或一个空间中的每一个点在相同方向移动相同距离。比如对图像分类任务来说，图像中的目标不管被移动到图片的哪个位置，得到的结果（标签）应该是相同的，这就是卷积神经网络中的平移不变性。平移不变性意味着系统产生完全相同的响应（输出），不管它的输入是如何平移的 。</p>

        <h5 id="1-2-旋转不变性">
          <a href="#1-2-旋转不变性" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-2-旋转不变性" class="headerlink" title="1.2 旋转不变性"></a>1.2 旋转不变性</h5>
      <p>旋转不变性：只要对特征定义了方向，然后在同一个方向上进行特征描述就可以实现旋转不变性。</p>

        <h5 id="1-3-尺度不变性">
          <a href="#1-3-尺度不变性" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-3-尺度不变性" class="headerlink" title="1.3 尺度不变性"></a>1.3 尺度不变性</h5>
      <p>为了实现尺度不变性，需要给特征加上尺度因子。在进行特征描述的时候，将尺度统一就可以实现尺度不变性了。</p>

        <h5 id="对于旋转不变性和尺度不变性的理解">
          <a href="#对于旋转不变性和尺度不变性的理解" class="heading-link"><i class="fas fa-link"></i></a><a href="#对于旋转不变性和尺度不变性的理解" class="headerlink" title="对于旋转不变性和尺度不变性的理解"></a>对于旋转不变性和尺度不变性的理解</h5>
      <p>参考链接：<span class="exturl"><a class="exturl__link" target="_blank" rel="noopener" href="https://blog.csdn.net/julialove102123/article/details/80822076">特征提取（Detect）、特征描述（Descriptor）、特征匹配（Match）的通俗解释_女王の专属领地-CSDN博客</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></p>
<p>简而言之为了使图像在旋转、放缩后，模型仍然能做出正确的判断(即不会影响模型对此图像的特征提取)，需要给特征指定一个方向与尺度。对于旋转来说，旋转之后特征方向也跟着转，所以相对来说图像的特征方向没有发生变化，如图1所示。指定尺度之后也实现了放缩不影响，如图2。</p>
<p><img src="/images/Convolutional%20Neural%20Networks/image-20211011095359772.png" alt="image-20211011095359772"></p>
<p>​                                                                                                            图1 旋转不变性，指定了特征方向</p>
<p><img src="/images/Convolutional%20Neural%20Networks/image-20211011095224160.png" alt="image-20211011095224160"></p>
<p>​                                                                                                                图2 尺度不变性 </p>

        <h4 id="二、卷积操作">
          <a href="#二、卷积操作" class="heading-link"><i class="fas fa-link"></i></a><a href="#二、卷积操作" class="headerlink" title="二、卷积操作"></a>二、卷积操作</h4>
      
        <h5 id="2-1-卷积运算">
          <a href="#2-1-卷积运算" class="heading-link"><i class="fas fa-link"></i></a><a href="#2-1-卷积运算" class="headerlink" title="2.1 卷积运算"></a>2.1 卷积运算</h5>
      <p>卷积运算的定义非常简单，将卷积核从输入张量的左上角进行从上到下、从左到右的滑动。每滑动到一个新位置，卷积核与输入张量的对应位置上的元素依次相乘再累加，当卷积核滑动过整个输入张量的时候也就得到了卷积运算的结果。计算结果如图所示：</p>
<p><img src="/images/Convolutional%20Neural%20Networks/image-20211015175532717.png" alt="image-20211015175532717"></p>
<p>​                                                                                                                图3 卷积操作的运算过程</p>
<p>如上图所示，计算卷积操作的第一个结果19 = 0×0 + 1×1 +3×2 + 4×3，依次在这个3*3的输入张量上滑动卷积核得到2×2的卷积输出。</p>

        <h5 id="2-2-输出尺寸的计算">
          <a href="#2-2-输出尺寸的计算" class="heading-link"><i class="fas fa-link"></i></a><a href="#2-2-输出尺寸的计算" class="headerlink" title="2.2 输出尺寸的计算"></a>2.2 输出尺寸的计算</h5>
      <p>如上图3所示，经过卷积操作之后，输出的尺寸会比原本的输入尺寸有所缩小。输出的尺寸计算公式为</p>
<p><img src="/images/Convolutional%20Neural%20Networks/image-20211015200610183.png" alt="image-20211015200610183"></p>
<p>如上图，3×3的输入张量，2×2的卷积核，（3-2+1）×（3-2+1）=2×2。</p>

        <h5 id="2-3-特征映射（特征图Feature-Map-与感受野">
          <a href="#2-3-特征映射（特征图Feature-Map-与感受野" class="heading-link"><i class="fas fa-link"></i></a><a href="#2-3-特征映射（特征图Feature-Map-与感受野" class="headerlink" title="2.3 特征映射（特征图Feature Map)与感受野"></a>2.3 特征映射（特征图Feature Map)与感受野</h5>
      <p>卷积层的输出有时也被称为<strong>特征映射Feature Map</strong>。因为卷积层可以视为一个输入映射到下一层的空间维度的转换器。</p>
<p>对于每一层的元素<em><strong>x</strong></em>,其感受野（Receptive Field）是指前向传播期间可能影响x计算的来自所有先前层的所有元素。如上图3所示的卷积操作为例，元素19的感受野来自前置的0，1，3，4四个元素。如果在输出后面再加一层卷积层，卷积核为不变的2×2卷积核，可以得到一个单个元素的输出z，则这个单个元素的感受野为上层的4个元素，上层的4个元素又来自输入的全部9个元素，故感受野包括全部的13个元素。因此，当一个特征图中的任意元素需要检测更广区域的输入特征时，我们可以构建一个更深的网络。</p>

        <h5 id="2-4-卷积的作用到底是什么">
          <a href="#2-4-卷积的作用到底是什么" class="heading-link"><i class="fas fa-link"></i></a><a href="#2-4-卷积的作用到底是什么" class="headerlink" title="2.4 卷积的作用到底是什么"></a>2.4 卷积的作用到底是什么</h5>
      <p>回忆下全连接层在做什么：<strong>全连接的核心在于矩阵向量乘积</strong>，公式为<strong>y = Wx + b</strong>。以图片分类举例，采用全连接层首先要把二维的图片<strong>28×28拉成1×784的向量x</strong>，W为预置的参数向量，而<strong>y</strong>是对图片预测的分类label。全连接层完成的功能是提供一组参数w，将图片(向量x)映射到label(y)。</p>
<p><strong>如果将全连接层用于较大的图片分类会出现什么问题？</strong></p>
<ul>
<li><strong>一张28×28的图片，需要的参数数量是784个。即图片的每一个像素都需要一个参数，图片较大的时候参数的数量非常巨大，难以进行训练。很容易出现过拟合等问题</strong></li>
<li><strong>直接使用全连接层需要将图片拉平，在这个操作中像素之间的位置发生了变化，空间信息被破坏。</strong></li>
</ul>
<p>而卷积在做什么？</p>
<p>卷积核是一个在图片上滑动的小块，<strong>在卷积核的每个位置也是一个参数</strong>。卷积核在滑动的时候每次与图片的一个小区域进行计算，在这个过程中图片像素的位置没有发生变化，因此，<strong>在卷积操作中像素之间的空间位置信息得到了很好的保留。</strong></p>
<p>其次，卷积核每次与图片的每个小区域进行相乘再相加操作，计算完成之后得到一个特征映射Feature Map，这个Feature Map可以理解成本层卷积层提取出的特征，<strong>经过多层运算之后也将图片(向量x)映射到label(y)。</strong>所以卷积与全连接的最终都是完成了将图片的特征提取出来经过运算映射到label的功能。</p>
<p>但是在卷积过程中，很多个像素共同使用一个卷积核，即使用同一组参数。实现了<strong>权值共享</strong>，降低了参数的数量。</p>
<p><strong>卷积层可以看作是计算量和准确度的一种妥协。</strong></p>

        <h4 id="三、控制输出尺寸的手段–填充和步幅">
          <a href="#三、控制输出尺寸的手段–填充和步幅" class="heading-link"><i class="fas fa-link"></i></a><a href="#三、控制输出尺寸的手段–填充和步幅" class="headerlink" title="三、控制输出尺寸的手段–填充和步幅"></a>三、控制输出尺寸的手段–填充和步幅</h4>
      <p>由第二章可知，进行卷积操作会改变输入的尺寸。并且输入张量的边界上的特征并没有经过充分的提取，原始图像的边界丢失了很多有用的信息。<strong>填充</strong>（padding）是解决这一问题的有效方法。经过填充操作可以将输出的尺寸控制的与输入尺寸相同。但有时我们我们发现原始的输入分辨率十分冗余。 <em><strong>步幅</strong></em>（stride）则可以在这类情况下提供帮助。</p>

        <h5 id="3-1-填充操作">
          <a href="#3-1-填充操作" class="heading-link"><i class="fas fa-link"></i></a><a href="#3-1-填充操作" class="headerlink" title="3.1 填充操作"></a>3.1 填充操作</h5>
      <p>在应用多层卷积时，我们常常丢失边缘像素。 由于我们通常使用小卷积核，因此对于任何单个卷积，我们可能只会丢失几个像素。 但随着我们应用许多连续卷积层，累积丢失的像素数就多了。 解决这个问题的简单方法即为<em>填充</em>（padding）：在输入图像的边界填充元素（通常填充元素是 0 ）。 如下图所示，对输入图像做填充操作后，输出的尺寸从2×2增加到了4×4。对于边缘的元素来说，以第一个0元素为例，在进行不填充的卷积操作之后（如图3），输入图片的第一个元素0只能映射到输出的第一个元素19上，经过多次卷积操作之后元素0所含的信息可能会丢失。而进行填充操作之后（如下图4），可见第一个0元素分别映射到了输出的0，3，9，19四个元素上。可见边缘信息得到了很好的提取与保留。</p>
<p><img src="/images/Convolutional%20Neural%20Networks/image-20211017084611169.png" alt="image-20211017084611169"></p>
<p>​                                                                                    图4 填充之后的卷积操作，填充在原始图像上做了一行和一列的扩充</p>
<p>填充后的尺寸计算公式为：</p>
<p><img src="/images/Convolutional%20Neural%20Networks/image-20211017085013039.png" alt="image-20211017085013039"></p>
<p>其中输入的尺寸为nh×nw，卷积核的尺寸为kh×kw，添加 ph 行填充（大约一半在顶部，一半在底部）和 pw列填充（左侧大约一半，右侧一半）。</p>

        <h5 id="3-2-Pytorch的卷积操作的一些参数小细节">
          <a href="#3-2-Pytorch的卷积操作的一些参数小细节" class="heading-link"><i class="fas fa-link"></i></a><a href="#3-2-Pytorch的卷积操作的一些参数小细节" class="headerlink" title="3.2 Pytorch的卷积操作的一些参数小细节"></a>3.2 Pytorch的卷积操作的一些参数小细节</h5>
      <p>Pytorch的卷积操作Conv2d的参数如图所示：</p>
<p><img src="/images/Convolutional%20Neural%20Networks/image-20211017090938756.png" alt="image-20211017090938756"></p>
<p><img src="/images/Convolutional%20Neural%20Networks/image-20211017091005294.png" alt="image-20211017091005294"></p>
<p><img src="/images/Convolutional%20Neural%20Networks/image-20211017091018257.png" alt="image-20211017091018257"></p>
<p>其实需要特别注意的只有第三张图片，kernel_size,stride,padding的值可以设置为单个int也可以设置成tuple形式。当设置成单个int的形式的时候，如设置kernel_size=3，实际上是将kernel_size设置成3×3，设置成单个int的时候实际上是把该参数的height和width维度设置成相同的int值。当设置成tuple的时候就是按照该tuple来设置高度和宽度。</p>
<p>对于填充padding操作，一个小细节是当padding设置成单个int的时候，实际上是对上下左右四条边上分别填充了int行和int列。如设置padding=1时就是如下图的效果，在使用上述的计算公式的时候要注意，此时的ph应当=2而不是1。因为添加ph行填充一半在顶部一半在底部。padding=1分别对顶部和底部以及左右分别添加了1行或1列。因此ph应该=2。当输入为一个8×8的Tensor的时候，输出的size应该为（8-3+2+1）×（8-3+2+1）=8×8。</p>
<p><img src="/images/Convolutional%20Neural%20Networks/image-20211017091845369.png" alt="image-20211017091845369"></p>

        <h5 id="3-3-Tips">
          <a href="#3-3-Tips" class="heading-link"><i class="fas fa-link"></i></a><a href="#3-3-Tips" class="headerlink" title="3.3 Tips"></a>3.3 Tips</h5>
      <p><strong>卷积神经网络中卷积核的高度和宽度通常为奇数，例如 1、3、5 或 7。</strong> 选择奇数的好处是，保持空间维度的同时，我们可以在顶部和底部填充相同数量的行，在左侧和右侧填充相同数量的列。</p>
<p>此外，使用奇数核和填充也提供了书写上的便利。对于任何二维张量 <code>X</code>，当满足： 1. 内核的大小是奇数； 2. 所有边的填充行数和列数相同； 3. 输出与输入具有相同高度和宽度 则可以得出：输出 <code>Y[i, j]</code> 是通过以输入 <code>X[i, j]</code> 为中心，与卷积核进行互相关计算得到的。</p>

        <h5 id="3-4-步幅stride">
          <a href="#3-4-步幅stride" class="heading-link"><i class="fas fa-link"></i></a><a href="#3-4-步幅stride" class="headerlink" title="3.4 步幅stride"></a>3.4 步幅stride</h5>
      <p>在卷积计算中，卷积核从输入张量左上角开始，向下和向右滑动。 在前面的例子中，我们默认每次滑动一个元素。 但是，有时候为了高效计算或是缩减采样次数，卷积窗口可以跳过中间位置，每次滑动多个元素。我们将每次滑动元素的数量称为 <em>步幅</em> （stride）。</p>
<p>可以看到，为了计算输出中第一列的第二个元素和第一行的第二个元素，卷积窗口分别向下滑动三行和向右滑动两列。但是，当卷积窗口继续向右滑动两列时，没有输出，因为输入元素无法填充窗口（除非我们添加另一列填充）。</p>
<p><img src="/images/Convolutional%20Neural%20Networks/image-20211017093508072.png" alt="image-20211017093508072"></p>
<p>通常，当垂直步幅为 sh 、水平步幅为 sw 时，输出形状为</p>
<p><img src="/images/Convolutional%20Neural%20Networks/image-20211017093554956.png" alt="image-20211017093554956"></p>

        <h4 id="四、通道">
          <a href="#四、通道" class="heading-link"><i class="fas fa-link"></i></a><a href="#四、通道" class="headerlink" title="四、通道"></a>四、通道</h4>
      <p>标准的彩色图像一般都具有RGB三个通道来分别指示红绿蓝。因此一个标准的RGB图像的张量表示应当是一个三维的张量，size为3×h×w。我们将第一个维度称为通道channel。</p>

        <h5 id="4-1-多输入通道上的卷积操作">
          <a href="#4-1-多输入通道上的卷积操作" class="heading-link"><i class="fas fa-link"></i></a><a href="#4-1-多输入通道上的卷积操作" class="headerlink" title="4.1 多输入通道上的卷积操作"></a>4.1 多输入通道上的卷积操作</h5>
      <p>一句话概括就是在多输入通道上的卷积操作其实是分别对每个通道上的二维张量对该通道上的卷积核做卷积运算。如下图，以两通道为例：</p>
<p><img src="/images/Convolutional%20Neural%20Networks/image-20211017153347989.png" alt="image-20211017153347989"></p>

        <h5 id="4-2-控制输出通道数量的手段–1-1卷积层">
          <a href="#4-2-控制输出通道数量的手段–1-1卷积层" class="heading-link"><i class="fas fa-link"></i></a><a href="#4-2-控制输出通道数量的手段–1-1卷积层" class="headerlink" title="4.2 控制输出通道数量的手段–1*1卷积层"></a>4.2 控制输出通道数量的手段–1*1卷积层</h5>
      <p>由卷积操作的定义可知，卷积操作的本质是提取相邻像素之间的相关特征，因此如果仅对单通道图像采用1×1卷积核做卷积运算似乎并没有什么意义。但是引入多通道之后，1×1的卷积在不同通道上有了累加运算。</p>
<p>1×1卷积的运算规则与普通卷积并没有什么区别。但是当卷积层包含多组1×1卷积核的时候，可以实现控制调整输出的通道数量，即<strong>数据的depth</strong>。如下图所示，输入为3通道的3×3的Tensor，卷积层包括两组3通道的1×1卷积核，最终输入Tensor分别对两组卷积核分别做1×1卷积计算，最终输出的通道数，即depth为2。</p>
<p><img src="/images/Convolutional%20Neural%20Networks/image-20211017164411266.png" alt="image-20211017164411266"></p>
<p>卷积的输出输入是长方体，所以1x1卷积实际上是对每个像素点，在不同的channels上进行线性组合（信息整合），且保留了图片的原有平面结构，调控depth，从而完成升维或降维的功能。 如上图所示，如果选择2个filters的1x1卷积层，那么数据就从原本的depth 3 降到了2。若用4个filters，则起到了升维的作用。</p>

        <h4 id="五、池化层">
          <a href="#五、池化层" class="heading-link"><i class="fas fa-link"></i></a><a href="#五、池化层" class="headerlink" title="五、池化层"></a>五、池化层</h4>
      
        <h5 id="5-1-池化操作">
          <a href="#5-1-池化操作" class="heading-link"><i class="fas fa-link"></i></a><a href="#5-1-池化操作" class="headerlink" title="5.1 池化操作"></a>5.1 池化操作</h5>
      <p>与卷积层相似，池化层同样有一个固定大小的窗口<strong>称为（池化窗口）</strong>，并根据步幅大小在输入的所有区域上滑动。通常来说池化运算是池化窗口在输入区域上滑动，求输入张量在池化窗口内的最大值或平均值。<strong>求最大值的称为最大值池化MaxPooling，求平均值的称为平均值池化average pooling</strong>。</p>
<p>在这两种情况下，与卷积操作一样，池化窗口从输入张量的左上角开始，从左到右、从上到下的在输入张量内滑动。在池化窗口到达的每个位置，它计算该窗口中输入子张量的最大值或平均值，具体取决于是使用了最大池化层还是平均池化层。</p>
<p><img src="/images/Convolutional%20Neural%20Networks/image-20211017172202113.png" alt="image-20211017172202113"></p>

        <h5 id="5-2-池化的意义">
          <a href="#5-2-池化的意义" class="heading-link"><i class="fas fa-link"></i></a><a href="#5-2-池化的意义" class="headerlink" title="5.2 池化的意义"></a>5.2 池化的意义</h5>
      <p>通常当我们处理图像时，我们希望逐渐降低隐藏表示的空间分辨率，聚集信息，这样随着我们在神经网络中层叠的上升，每个神经元对其敏感的感受野（输入）就越大。池化层有以下的一些作用：</p>
<p>（1）首要作用，下采样（downsamping），由于汇合操作的降采样作用，汇合结果中的一个元素对应于原输入数据的一个子区域（sub-region），因此汇合相当于在空间范围内做了维度约减（spatially dimension reduction），从而使模型可以抽取更广范围的特征。同时减小了下一层输入大小，进而减小计算量和参数个数。</p>
<p>（2）降维、去除冗余信息、对特征进行压缩、简化网络复杂度、减小计算量、减小内存消耗等等。各种说辞吧，总的理解就是减少参数量。</p>
<p>（3）实现非线性（这个可以想一下，relu函数，是不是有点类似的感觉？）。</p>
<p>（4）可以扩大感知野。</p>
<p>（5）可以实现不变性，其中不变形性包括，平移不变性、旋转不变性和尺度不变性。汇合操作使模型更关注是否存在某些特征而不是特征具体的位置<br>，可看作是一种很强的先验，使特征学习包含某种程度自由度，能容忍一些特征微小的位移。</p>
</div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2021/10/09/week%20summary001/">每周计划与总结001</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">发表于</span><span class="post-meta-item__value">2021-10-09</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">更新于</span><span class="post-meta-item__value">2021-10-09</span></span></div></header><div class="post-body"><div class="post-excerpt">
        <h4 id="前言">
          <a href="#前言" class="heading-link"><i class="fas fa-link"></i></a><a href="#前言" class="headerlink" title="前言"></a>前言</h4>
      <p>不知不觉就混吃等死混到了十月第一周都结束了。<del>本来打算十月开始就做一个，结果假期一拖就拖到了现在</del>。立个小目标每周不断更好吧TVT。</p>

        <h4 id="上周总结">
          <a href="#上周总结" class="heading-link"><i class="fas fa-link"></i></a><a href="#上周总结" class="headerlink" title="上周总结"></a>上周总结</h4>
      <p><del>上周为祖国母亲庆生所以摸了。</del>除了稍微过了下数理统计与矩阵论的课本与课件，和结束了长达半个月的《动手学深度学习》第五章。</p>
<p><img src="/images/week%20summary001/image-20211009160317243.png" alt="image-20211009160317243"></p>

        <h4 id="下周（10-11-10-17）计划">
          <a href="#下周（10-11-10-17）计划" class="heading-link"><i class="fas fa-link"></i></a><a href="#下周（10-11-10-17）计划" class="headerlink" title="下周（10.11-10.17）计划"></a>下周（10.11-10.17）计划</h4>
      <ul>
<li><p>《动手学深度学习》第六章结束</p>
</li>
<li><p>六级试卷*2</p>
</li>
<li><p>《算法导论》1-3章</p>
</li>
<li><p>《c++ Primer》3-4章</p>
</li>
<li><p>矩阵论、数理统计复习</p>
</li>
<li><p>睡前半小时《平凡的世界》<del>半年读了7章。。。从这周开始一定好好读书</del></p>
</li>
</ul>
<p>十月绝不摆烂！！！！</p>
<p><img src="/images/week%20summary001/image-20211009160233635.png" alt="image-20211009160233635"></p>
</div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2021/10/08/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/">深度学习计算</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">发表于</span><span class="post-meta-item__value">2021-10-08</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">更新于</span><span class="post-meta-item__value">2021-10-09</span></span></div></header><div class="post-body"><div class="post-excerpt">
        <h3 id="第五章-深度学习计算">
          <a href="#第五章-深度学习计算" class="heading-link"><i class="fas fa-link"></i></a><a href="#第五章-深度学习计算" class="headerlink" title="第五章 深度学习计算"></a>第五章 深度学习计算</h3>
      
        <h4 id="一、层和块">
          <a href="#一、层和块" class="heading-link"><i class="fas fa-link"></i></a><a href="#一、层和块" class="headerlink" title="一、层和块"></a>一、层和块</h4>
      
        <h5 id="1-1-块的概念">
          <a href="#1-1-块的概念" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-1-块的概念" class="headerlink" title="1.1 块的概念"></a>1.1 块的概念</h5>
      <p>为了实现更加复杂的网络，引入神经网络块的概念。块可以描述单个层、由多个层组成的组件或整个模型本身。使用块进行抽象的一个好处是可以将一些块组合成更大的组件，这一过程通常是递归的。</p>

        <h5 id="1-2-Pytorch中块的简洁实现">
          <a href="#1-2-Pytorch中块的简洁实现" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-2-Pytorch中块的简洁实现" class="headerlink" title="1.2 Pytorch中块的简洁实现"></a>1.2 Pytorch中块的简洁实现</h5>
      <p>之前学习的章节中一直在使用的nn.Sequential方法实际上就是定义了一个块。通过实例化<code>nn.Sequential</code>来构建我们的模型，层的执行顺序是作为参数传递的。简而言之，<code>nn.Sequential</code>定义了一种特殊的<code>Module</code>，即在PyTorch中表示一个块的类。它维护了一个由<code>Module</code>组成的有序列表，注意，两个全连接层都是<code>Linear</code>类的实例，<code>Linear</code>类本身就是<code>Module</code>的子类。正向传播（<code>forward</code>）函数也非常简单：它将列表中的每个块连接在一起，将每个块的输出作为下一个块的输入。</p>
<p>如：<code>net = nn.Sequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))</code></p>
<p>实际上就定义了一个块，块中包含了两个线性层和一个ReLU层。</p>

        <h5 id="1-3-自定义块">
          <a href="#1-3-自定义块" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-3-自定义块" class="headerlink" title="1.3 自定义块"></a>1.3 自定义块</h5>
      <p><code>Sequential</code>类使模型构造变得简单，允许我们组合新的结构，而不必定义自己的类。然而，并不是所有的架构都是简单的顺序结构。当需要更大的灵活性时，我们需要定义自己的块。例如，我们可能希望在正向传播函数中执行Python的控制流。此外，我们可能希望执行任意的数学运算，而不是简单地依赖预定义的神经网络层。</p>
<p>自定义块必须提供的基本功能：</p>
<ol>
<li>将输入数据作为其正向传播函数的参数。</li>
<li>通过正向传播函数来生成输出。请注意，输出的形状可能与输入的形状不同。例如，我们上面模型中的第一个全连接的层接收任意维的输入，但是返回一个维度256的输出。</li>
<li>计算其输出关于输入的梯度，可通过其反向传播函数进行访问。通常这是自动发生的。</li>
<li>存储和访问正向传播计算所需的参数。</li>
<li>根据需要初始化模型参数。</li>
</ol>

        <h4 id="二、参数管理">
          <a href="#二、参数管理" class="heading-link"><i class="fas fa-link"></i></a><a href="#二、参数管理" class="headerlink" title="二、参数管理"></a>二、参数管理</h4>
      <p>假设模型是一个具有单隐藏层的多层感知机。</p>
<p>``</p>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line">net = nn.Sequential(nn.Linear(<span class="number">4</span>, <span class="number">8</span>), nn.ReLU(), nn.Linear(<span class="number">8</span>, <span class="number">1</span>))</span><br><span class="line">X = torch.rand(size=(<span class="number">2</span>, <span class="number">4</span>))</span><br><span class="line">net(X)</span><br></pre></td></tr></table></div></figure>


        <h5 id="2-1-参数访问">
          <a href="#2-1-参数访问" class="heading-link"><i class="fas fa-link"></i></a><a href="#2-1-参数访问" class="headerlink" title="2.1 参数访问"></a>2.1 参数访问</h5>
      <p>当通过Sequential类定义模型时，由于Sequential类似于一个Module的列表，可以通过索引来访问模型的任意层。可以通过以下方法检查第二个全连接层的参数</p>
<p><code>print(net[2].state_dict())</code></p>
<p>输出为</p>
<p>OrderedDict([(‘weight’, tensor([[-0.0578,  0.2847,  0.0501, -0.1246,  0.2490, -0.0303,  0.1356,  0.2373]])), (‘bias’, tensor([0.1629]))])</p>
<p>显然第二个全连接层有两个参数，weight和bias，可以通过  <code>net[2].bias</code> 访问参数，通过  <code>net[2].bias.data</code> 得到bias的实际的数值，也可以通过.grad来访问具体参数的梯度值。</p>

        <h5 id="2-2-一次性访问所有参数">
          <a href="#2-2-一次性访问所有参数" class="heading-link"><i class="fas fa-link"></i></a><a href="#2-2-一次性访问所有参数" class="headerlink" title="2.2 一次性访问所有参数"></a>2.2 一次性访问所有参数</h5>
      <p>可以通过Module.named_parameters()方法一次性访问查看一个层或者一个网络的所有参数</p>
<p>例：查看第一层的所有参数的数据大小</p>
<p><code>print(*[(name, parameter.shape) for name, parameter in net[0].named_parameters()])</code></p>
<p>查看整个网络的全部参数</p>
<p><code>print(*[(name, parameter) for name, parameter in net.named_parameters()])</code></p>
<p>自定义的网络层亦可以使用相同方式查看参数</p>

        <h5 id="2-3-参数初始化">
          <a href="#2-3-参数初始化" class="heading-link"><i class="fas fa-link"></i></a><a href="#2-3-参数初始化" class="headerlink" title="2.3 参数初始化"></a>2.3 参数初始化</h5>
      <p>参数初始化的常用方法是编写一个函数调用内置初始化器，然后使用module.apply()函数应用初始化方法。</p>
<p>例：将参数以正态分布初始化</p>
<p>`</p>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">init_normal</span>(<span class="params">m</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">type</span>(m) == nn.Linear:</span><br><span class="line">        nn.init.normal_(m.weight, mean=<span class="number">0</span>, std=<span class="number">0.01</span>)</span><br><span class="line">        nn.init.zeros_(m.bias)</span><br><span class="line">net.apply(init_normal)</span><br></pre></td></tr></table></div></figure>

<p>`</p>
<p>可以定义多个初始化方法，分别应用与不同的层</p>
<p>`</p>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">xavier</span>(<span class="params">m</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">type</span>(m) == nn.Linear:</span><br><span class="line">        nn.init.xavier_uniform_(m.weight)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">init_42</span>(<span class="params">m</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">type</span>(m) == nn.Linear:</span><br><span class="line">        nn.init.constant_(m.weight, <span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">net[<span class="number">0</span>].apply(xavier)</span><br><span class="line">net[<span class="number">2</span>].apply(init_42)</span><br></pre></td></tr></table></div></figure>

<p>`</p>

        <h4 id="三、自定义层">
          <a href="#三、自定义层" class="heading-link"><i class="fas fa-link"></i></a><a href="#三、自定义层" class="headerlink" title="三、自定义层"></a>三、自定义层</h4>
      <p>有时需要完成一些深度学习框架内未提供的功能，需要通过自定义层来实现。只需要继承基础层类(nn.Module)实现正向传播即可。</p>

        <h4 id="3-1-不带参数的层">
          <a href="#3-1-不带参数的层" class="heading-link"><i class="fas fa-link"></i></a><a href="#3-1-不带参数的层" class="headerlink" title="3.1 不带参数的层"></a>3.1 不带参数的层</h4>
      <p>例：定义一个层次实现从输入中减去均值。</p>
<p>`</p>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CenteredLayer</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">     </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, X</span>):</span></span><br><span class="line">        <span class="keyword">return</span> X - X.mean()</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">layer = CenteredLayer()</span><br><span class="line">layer(torch.FloatTensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]))</span><br></pre></td></tr></table></div></figure>

<p>`</p>
<p>输出为：</p>
<p><code>tensor([-2., -1.,  0.,  1.,  2.])</code></p>

        <h4 id="3-2-带参数的层">
          <a href="#3-2-带参数的层" class="heading-link"><i class="fas fa-link"></i></a><a href="#3-2-带参数的层" class="headerlink" title="3.2 带参数的层"></a>3.2 带参数的层</h4>
      <p>我们也可以定义带参数的层，这些参数可以通过训练进行调整。我们可以使用内置函数来创建参数，这些函数提供一些基本的管理功能。比如管理访问、初始化、共享、保存和加载模型参数。</p>
<p>例：定义实现一个全连接层，并使用ReLU激活函数处理输出。</p>
<p>`</p>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyLinear</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_units, units</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.weight = nn.Parameter(torch.randn(in_units, units))</span><br><span class="line">        self.bias = nn.Parameter(torch.randn(units,))</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, X</span>):</span></span><br><span class="line">        linear = torch.matmul(X, self.weight.data) + self.bias.data</span><br><span class="line">        <span class="keyword">return</span> F.relu(linear)</span><br></pre></td></tr></table></div></figure>

<p>`</p>

        <h4 id="四、读取与保存参数和模型">
          <a href="#四、读取与保存参数和模型" class="heading-link"><i class="fas fa-link"></i></a><a href="#四、读取与保存参数和模型" class="headerlink" title="四、读取与保存参数和模型"></a>四、读取与保存参数和模型</h4>
      <p>当我们对所训练出的模型足够满意，可以使用Pytorch提供的一些方法保存训练好的模型与参数以用来直接推理。此外，当运行一个耗时较长的训练过程时，最佳的做法是定期保存中间结果（检查点），以确保在服务器电源被不小心断掉时不会损失几天的计算结果。</p>

        <h4 id="4-1-state-dict">
          <a href="#4-1-state-dict" class="heading-link"><i class="fas fa-link"></i></a><a href="#4-1-state-dict" class="headerlink" title="4.1 state_dict"></a>4.1 state_dict</h4>
      <p>state_dict是一个Python字典，它保存所有层与它的parameter tensor的映射。但是只有具有可学习参数的(torch.nn.Module)层和Registered buffers (batchnorm’s running_mean)才会在state_dict中有条目。同时优化器对象也有一个<em>state_dict</em>，其中包含有关优化器状态的信息，以及使用的超参数。</p>
<p>例：</p>
<p>`</p>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Define model</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TheModelClass</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(TheModelClass, self).__init__()</span><br><span class="line">        <span class="comment">#自定义参数层</span></span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">6</span>, <span class="number">5</span>)</span><br><span class="line">        self.pool = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, <span class="number">5</span>)</span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>, <span class="number">120</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">120</span>, <span class="number">84</span>)</span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = self.pool(F.relu(self.conv1(x)))</span><br><span class="line">        x = self.pool(F.relu(self.conv2(x)))</span><br><span class="line">        x = x.view(-<span class="number">1</span>, <span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>)</span><br><span class="line">        x = F.relu(self.fc1(x))</span><br><span class="line">        x = F.relu(self.fc2(x))</span><br><span class="line">        x = self.fc3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize model</span></span><br><span class="line">model = TheModelClass()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize optimizer</span></span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=<span class="number">0.001</span>, momentum=<span class="number">0.9</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print model&#x27;s state_dict</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Model&#x27;s state_dict:&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> param_tensor <span class="keyword">in</span> model.state_dict():</span><br><span class="line">    <span class="built_in">print</span>(param_tensor, <span class="string">&quot;\t&quot;</span>, model.state_dict()[param_tensor].size())</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print optimizer&#x27;s state_dict</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Optimizer&#x27;s state_dict:&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> var_name <span class="keyword">in</span> optimizer.state_dict():</span><br><span class="line">    <span class="built_in">print</span>(var_name, <span class="string">&quot;\t&quot;</span>, optimizer.state_dict()[var_name])</span><br></pre></td></tr></table></div></figure>

<p>`</p>
<p>输出：</p>
<p>`</p>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">Model<span class="string">&#x27;s state_dict:</span></span><br><span class="line"><span class="string">conv1.weight     torch.Size([6, 3, 5, 5])</span></span><br><span class="line"><span class="string">conv1.bias   torch.Size([6])</span></span><br><span class="line"><span class="string">conv2.weight     torch.Size([16, 6, 5, 5])</span></span><br><span class="line"><span class="string">conv2.bias   torch.Size([16])</span></span><br><span class="line"><span class="string">fc1.weight   torch.Size([120, 400])</span></span><br><span class="line"><span class="string">fc1.bias     torch.Size([120])</span></span><br><span class="line"><span class="string">fc2.weight   torch.Size([84, 120])</span></span><br><span class="line"><span class="string">fc2.bias     torch.Size([84])</span></span><br><span class="line"><span class="string">fc3.weight   torch.Size([10, 84])</span></span><br><span class="line"><span class="string">fc3.bias     torch.Size([10])</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Optimizer&#x27;</span>s state_dict:</span><br><span class="line">state    &#123;&#125;</span><br><span class="line">param_groups     [&#123;<span class="string">&#x27;lr&#x27;</span>: <span class="number">0.001</span>, <span class="string">&#x27;momentum&#x27;</span>: <span class="number">0.9</span>, <span class="string">&#x27;dampening&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;weight_decay&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;nesterov&#x27;</span>: <span class="literal">False</span>, <span class="string">&#x27;params&#x27;</span>: [<span class="number">4675713712</span>, <span class="number">4675713784</span>, <span class="number">4675714000</span>, <span class="number">4675714072</span>, <span class="number">4675714216</span>, <span class="number">4675714288</span>, <span class="number">4675714432</span>, <span class="number">4675714504</span>, <span class="number">4675714648</span>, <span class="number">4675714720</span>]&#125;]</span><br></pre></td></tr></table></div></figure>

<p>`</p>

        <h4 id="4-2-保存和加载模型">
          <a href="#4-2-保存和加载模型" class="heading-link"><i class="fas fa-link"></i></a><a href="#4-2-保存和加载模型" class="headerlink" title="4.2 保存和加载模型"></a>4.2 保存和加载模型</h4>
      
        <h5 id="4-2-1-推荐方式：保存-加载state-dict">
          <a href="#4-2-1-推荐方式：保存-加载state-dict" class="heading-link"><i class="fas fa-link"></i></a><a href="#4-2-1-推荐方式：保存-加载state-dict" class="headerlink" title="4.2.1 推荐方式：保存/加载state_dict"></a>4.2.1 推荐方式：保存/加载state_dict</h5>
      <p>保存模型进行推理时，只需要保存训练好的模型的学习参数即可。使用该函数保存模型的<em>state_dict</em><code>torch.save()</code>将为以后恢复模型提供最大的灵活性，这就是为什么它是保存模型的推荐方法。</p>
<p>一个常见的 PyTorch 约定是使用<code>.pt</code>或 <code>.pth</code>文件扩展名保存模型。</p>
<p>请记住，在运行推理之前，必须调用<code>model.eval()</code>将 dropout 和批处理规范化层设置为评估模式。不这样做会产生不一致的推理结果。</p>
<p>保存：</p>
<p><code>torch.save(model.state_dict(), PATH)</code></p>
<p>加载：</p>
<p>`</p>
<figure class="highlight plaintext"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model = TheModelClass(*args, **kwargs)</span><br><span class="line">model.load_state_dict(torch.load(PATH))</span><br><span class="line">model.eval()</span><br></pre></td></tr></table></div></figure>

<p>`</p>
<p>对上述定义的model进行保存和加载state_dict验证：</p>
<p>`</p>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 实例化module类，生成一个模型，使用torch.save保存state_dict</span></span><br><span class="line">model = TheModelClass()</span><br><span class="line">torch.save(model.state_dict(), <span class="string">&#x27;load_module1.params&#x27;</span>)</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=<span class="number">0.001</span>, momentum=<span class="number">0.9</span>)</span><br><span class="line"><span class="comment"># 加载模型参数，需要实例化一个相同的网络模型，调用load_state_dict(torch.load(PATH))加载保存的参数state_dict</span></span><br><span class="line">clone = TheModelClass()</span><br><span class="line">clone.load_state_dict(torch.load(<span class="string">&#x27;load_module1.params&#x27;</span>))</span><br><span class="line">clone.<span class="built_in">eval</span>()</span><br><span class="line"><span class="comment"># 验证参数是否相同</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Model&#x27;s state_dict&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> param_tensor <span class="keyword">in</span> model.state_dict():</span><br><span class="line">    <span class="built_in">print</span>(param_tensor, <span class="string">&quot;\t&quot;</span>, model.state_dict()[param_tensor] == clone.state_dict()[param_tensor])</span><br></pre></td></tr></table></div></figure>

<p>`</p>
<p><img src="/images/deepcompute/deepcompute.png" alt="image-20211008162402538"></p>

        <h5 id="4-2-2-保存整个模型">
          <a href="#4-2-2-保存整个模型" class="heading-link"><i class="fas fa-link"></i></a><a href="#4-2-2-保存整个模型" class="headerlink" title="4.2.2 保存整个模型"></a>4.2.2 保存整个模型</h5>
      <p>保存整个模型，在加载的时候就可以不用再实例化，直接<code>model = torch.load(PATH))</code>即可</p>
<p>保存：</p>
<p><code>torch.save(model, PATH)</code></p>
<p>加载：</p>
<p>`</p>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 前提条件是这个模型类已经在某处定义</span></span><br><span class="line">model = torch.load(PATH))</span><br><span class="line">model.<span class="built_in">eval</span>()</span><br></pre></td></tr></table></div></figure>

<p>`</p>

        <h5 id="4-2-3-检查点方式（checkpoints）">
          <a href="#4-2-3-检查点方式（checkpoints）" class="heading-link"><i class="fas fa-link"></i></a><a href="#4-2-3-检查点方式（checkpoints）" class="headerlink" title="4.2.3 检查点方式（checkpoints）"></a>4.2.3 检查点方式（checkpoints）</h5>
      <p><del>暂未遇见，以后填坑</del></p>
</div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2021/09/08/Softmax/">Softmax的Pytorch实现分类任务</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">发表于</span><span class="post-meta-item__value">2021-09-08</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">更新于</span><span class="post-meta-item__value">2021-09-15</span></span></div></header><div class="post-body"><div class="post-excerpt">
        <h4 id="一、Softmax回归的相关原理">
          <a href="#一、Softmax回归的相关原理" class="heading-link"><i class="fas fa-link"></i></a><a href="#一、Softmax回归的相关原理" class="headerlink" title="一、Softmax回归的相关原理"></a>一、Softmax回归的相关原理</h4>
      
        <h4 id="1、Softmax的引入">
          <a href="#1、Softmax的引入" class="heading-link"><i class="fas fa-link"></i></a><a href="#1、Softmax的引入" class="headerlink" title="1、Softmax的引入"></a>1、Softmax的引入</h4>
      <p>在机器学习和深度学习中，分类和回归是常见的两个问题。其中回归模型往往是通过输入一系列的特征，经过一定的处理输出一个预测值，如通过输入房屋的面积、房间数量等特征通过回归模型可以预测得到这间房屋的价格。而分类问题往往希望通过输入一些特征得到一个分类。如输入一张图像输入这张图像的类别(如是猫还是狗)。在实际的操作中，我们对硬性类别感兴趣，即属于何种类别。但我们往往得到的是软性类别，即得到属于每个类别的概率，概率最大的类别即为类别的预测值。得到这种概率的结果往往并不困难，只需要在简单的线性模型的输出层前套一层softmax函数即可实现。</p>

        <h4 id="2、Softmax函数">
          <a href="#2、Softmax函数" class="heading-link"><i class="fas fa-link"></i></a><a href="#2、Softmax函数" class="headerlink" title="2、Softmax函数"></a>2、Softmax函数</h4>
      <p>由上所述，分类问题的重点是如何将模型的输出映射成概率。SoftMax函数的功能就是将多个神经元的输出映射到（0，1）的区间内，从而将这种输出看作概率。下图非常清晰的显示了Softmax的计算过程。</p>
<p><img src="/images/softmax-1.png" alt="upload successful"><br>假设有一个数组V，Vi表示数组中第i个元素，则该元素的Softmax值为</p>
<p><img src="/images/softmax-2.png" alt="upload successful"><br>softmax直白来说就是将原来神经元的输出3,1,-3套上softmax函数映射成为取值范围为(0,1)的值，而这些值的累和为1（满足概率的性质），那么我们就可以将它理解成概率，在最后选取输出结点的时候，我们就可以选取概率最大（也就是值对应最大的）结点，作为我们的预测结果进行输出。</p>

        <h4 id="3、交叉熵损失函数">
          <a href="#3、交叉熵损失函数" class="heading-link"><i class="fas fa-link"></i></a><a href="#3、交叉熵损失函数" class="headerlink" title="3、交叉熵损失函数"></a>3、交叉熵损失函数</h4>
      <p>在分类问题中，尤其是在神经网络中，交叉熵函数非常常见。因为经常涉及到分类问题，需要计算各类别的概率，所以交叉熵损失函数又都是与sigmoid函数或者softmax函数成对出现。</p>
<p>比如用神经网络最后一层作为概率输出，一般最后一层神经网络的计算方式如下：<br>1.网络的最后一层得到每个类别的scores。<br>2.score与sigmoid函数或者softmax函数进行计算得到概率输出。<br>3.第二步得到的类别概率与真实类别标签的one-hot形式进行交叉熵计算。<br>熵，熵的本质是香农信息量的期望。<br>熵在信息论中代表随机变量不确定度的度量。一个离散型随机变量X的熵 H(X)定义为：</p>
<p><img src="/images/softmax-3.png" alt="upload successful"><br>交叉熵刻画的是实际输出概率和期望输出概率的距离，交叉熵的值越小，则两个概率分布越接近，即实际与期望差距越小。假设概率分布p(xi)为期望输出，概率分布为q(xi)为实际输出，H(X)为交叉熵。则交叉熵的计算表达式为:</p>
<p><img src="/images/softmax-4.png" alt="upload successful"></p>

        <h3 id="二、Fashion-MNIST数据集">
          <a href="#二、Fashion-MNIST数据集" class="heading-link"><i class="fas fa-link"></i></a><a href="#二、Fashion-MNIST数据集" class="headerlink" title="二、Fashion-MNIST数据集"></a>二、Fashion-MNIST数据集</h3>
      
        <h4 id="1、简介">
          <a href="#1、简介" class="heading-link"><i class="fas fa-link"></i></a><a href="#1、简介" class="headerlink" title="1、简介"></a>1、简介</h4>
      <p>Fashion-MNIST 是一个替代 MNIST 手写数字集 的图像数据集。 它是由 Zalando（一家德国的时尚科技公司）旗下的研究部门提供。其涵盖了来自 10 种类别的共 7 万个不同商品的正面图片。<br>Fashion-MNIST 的大小、格式和训练集/测试集划分与原始的 MNIST 完全一致。60000/10000 的训练测试数据划分，28x28 的灰度图片。你可以直接用它来测试你的机器学习和深度学习算法性能，且不需要改动任何的代码。</p>

        <h4 id="2、数据集的内容">
          <a href="#2、数据集的内容" class="heading-link"><i class="fas fa-link"></i></a><a href="#2、数据集的内容" class="headerlink" title="2、数据集的内容"></a>2、数据集的内容</h4>
      <p>训练集和测试集数据的格式相同，通过获取迭代器的第一个元素可以得知，数据格式是一个具有两个元素的列表。第一个列表表示28*28图像的Tensor表示，第二个元素是一个1个元素的Tensor，它的取值为0-9，分别代表10类图像。</p>
<p><img src="/images/softmax1.png" alt="upload successful"></p>
<p><img src="/images/softmax.png" alt="upload successful"></p>

        <h3 id="三、具体代码实现">
          <a href="#三、具体代码实现" class="heading-link"><i class="fas fa-link"></i></a><a href="#三、具体代码实现" class="headerlink" title="三、具体代码实现"></a>三、具体代码实现</h3>
      
        <h4 id="1、使用到的包">
          <a href="#1、使用到的包" class="heading-link"><i class="fas fa-link"></i></a><a href="#1、使用到的包" class="headerlink" title="1、使用到的包"></a>1、使用到的包</h4>
      <p>``</p>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.utils <span class="keyword">import</span> data</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">&quot;ignore&quot;</span>)</span><br></pre></td></tr></table></div></figure>


        <h4 id="2、加载数据集">
          <a href="#2、加载数据集" class="heading-link"><i class="fas fa-link"></i></a><a href="#2、加载数据集" class="headerlink" title="2、加载数据集"></a>2、加载数据集</h4>
      <p>通过Pytorch中的<code>torchvision.datasets</code>提供的函数进行数据集的加载</p>
<p>``</p>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_data_fashion_mnist</span>(<span class="params">batch_size, resize=<span class="literal">None</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;获得数据集，并加载成iterable类型&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment">#定义转换函数trans，使用transforms.ToTensor()将图像转化成Tensor形式</span></span><br><span class="line">    <span class="comment">#class torchvision.transforms.ToTensor</span></span><br><span class="line">    <span class="comment">#把一个取值范围是[0,255]的PIL.Image或者shape为(H,W,C)的numpy.ndarray，转换成形状为[C,H,W]，取值范围是[0,1.0]的torch.FloadTensor</span></span><br><span class="line">    trans = [transforms.ToTensor()]</span><br><span class="line">    <span class="keyword">if</span> resize:</span><br><span class="line">        trans.insert(<span class="number">0</span>, transforms.Resize(resize))</span><br><span class="line">    trans = transforms.Compose(trans)</span><br><span class="line">    mnist_train = torchvision.datasets.FashionMNIST(root=<span class="string">&quot;../data&quot;</span>, train=<span class="literal">True</span>, transform=trans, download=<span class="literal">True</span>)</span><br><span class="line">    mnist_test = torchvision.datasets.FashionMNIST(root=<span class="string">&quot;../data&quot;</span>, train=<span class="literal">False</span>, transform=trans, download=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> (data.DataLoader(mnist_train, batch_size=batch_size, shuffle=<span class="literal">True</span>, num_workers=<span class="number">4</span>),</span><br><span class="line">            data.DataLoader(mnist_test, batch_size=batch_size, shuffle=<span class="literal">True</span>, num_workers=<span class="number">4</span>))</span><br></pre></td></tr></table></div></figure>

<p>其中，使用<code>ToTensor()</code>方法实际上是一种对图像的归一化处理。假设原图像是8位灰度图像，那么读入的像素矩阵最大值为256，最小值为1，定义矩阵为I，J＝I／256，就是归一化的图像矩阵，就是说归一化之后所有的像素值都在［0，1］区间内。</p>
<p>归一化处理的好处在于：<br>(1)归一化能够防止净输入绝对值过大引起的神经元输出饱和现象。<br>(2)归一化可以加快训练网络的收敛性.<del>（实际上不知道为什么要归一化，待进一步学习回来填坑）</del></p>
<p><code>transforms.Compose()</code>可以将多个转换函数组合在一起，参数是一个由转换函数组成的列表，如trans表示的那样。</p>
<p><code>torchvision.datasets.FashionMNIST(root=&quot;../data&quot;, train=True, transform=trans, download=True)</code><br>函数功能：使用<code>torchvision.datasets</code>提供的数据集加载方法下载并加载MNIST数据集<br>参数的解析：<code>root</code>：存放数据集的目录，<code>train</code>：True表示训练集，False表示测试集。 <code>download</code> : <code>True</code> = 从互联网上下载数据集, <code>transform</code>：转换函数，对数据集图像进行一些处理。</p>
<p><code>data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=4)</code><br>函数功能：</p>
<p><img src="/images/softmax3.png" alt="upload successful"></p>

        <h4 id="3、计算精确度">
          <a href="#3、计算精确度" class="heading-link"><i class="fas fa-link"></i></a><a href="#3、计算精确度" class="headerlink" title="3、计算精确度"></a>3、计算精确度</h4>
      <p>``</p>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">accuracy</span>(<span class="params">y_hat, y</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;函数功能：统计预测正确的数量&quot;&quot;&quot;</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;网络中输入batch_size*784,网络线性层784*10，结果为batch_size*10的矩阵，第二个维度为预测结果，最大的索引即为预测类别&quot;&quot;&quot;</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;numpy 返回最大的元素索引，def argmax(a, axis=None, out=None)</span></span><br><span class="line"><span class="string">    a—-输入array</span></span><br><span class="line"><span class="string">    axis—-为0代表列方向，为1代表行方向</span></span><br><span class="line"><span class="string">    out—-结果写到这个array里面&quot;&quot;&quot;</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;y.type:[序号]&quot;&quot;&quot;</span></span><br><span class="line">    y_hat = y_hat.argmax(axis=<span class="number">1</span>)</span><br><span class="line">    cmp = y_hat.<span class="built_in">type</span>(y.dtype) == y</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">float</span>(cmp.<span class="built_in">type</span>(y.dtype).<span class="built_in">sum</span>())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Accumulator</span>:</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;在n个变量上累加。&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment">#新建一个长度为n的列表，列表中每个元素都是一个待累加的变量</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, n</span>):</span></span><br><span class="line">        self.data = [<span class="number">0.0</span>] * n</span><br><span class="line">    <span class="comment">#add方法实现将data的值与add方法参数传入的值进行加和，zip方法实现将iterable对象打包成元组的列表</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    &gt;&gt;&gt;a = [1,2,3]</span></span><br><span class="line"><span class="string">    &gt;&gt;&gt; b = [4,5,6]</span></span><br><span class="line"><span class="string">    &gt;&gt;&gt; c = [4,5,6,7,8]</span></span><br><span class="line"><span class="string">    &gt;&gt;&gt; zipped = zip(a,b)     # 打包为元组的列表</span></span><br><span class="line"><span class="string">    [(1, 4), (2, 5), (3, 6)]</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add</span>(<span class="params">self, *args</span>):</span></span><br><span class="line">        self.data = [a + <span class="built_in">float</span>(b) <span class="keyword">for</span> a, b <span class="keyword">in</span> <span class="built_in">zip</span>(self.data, args)]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reset</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.data = [<span class="number">0.0</span>] * <span class="built_in">len</span>(self.data)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, idx</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.data[idx]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate_accuracy</span>(<span class="params">net, data_iter</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;计算在指定数据集上模型的精度&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(net, torch.nn.Module):</span><br><span class="line">        net.<span class="built_in">eval</span>()<span class="comment">#将模型置于评估模式，不计算梯度</span></span><br><span class="line">    metric = Accumulator(<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">for</span> X, y <span class="keyword">in</span> data_iter:</span><br><span class="line">        metric.add(accuracy(net(X), y), y.numel())<span class="comment">#numel()返回数组中元素个数</span></span><br><span class="line">    <span class="comment">#此时metric[0]存放的是网络中预测准确的个数，metric[1]存放数据集中的标签的总数</span></span><br><span class="line">    <span class="keyword">return</span> metric[<span class="number">0</span>] / metric[<span class="number">1</span>]</span><br></pre></td></tr></table></div></figure>


        <h4 id="4、定义网络结构">
          <a href="#4、定义网络结构" class="heading-link"><i class="fas fa-link"></i></a><a href="#4、定义网络结构" class="headerlink" title="4、定义网络结构"></a>4、定义网络结构</h4>
      <p>使用torch提供的<code>nn.Sequential</code>方法创建一个顺序容器，<code>Modules</code> 会以他们传入的顺序被添加到容器中。并使用使用torch提供的<code>nn.init</code>方法对线性层的权值<code>weight</code>初始化为均值为0，标准差为0.01的正态分布。</p>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Flatten层用来将输入“压平”，即把多维的输入一维化，常用在从卷积层到全连接层的过渡。Flatten不影响batch的大小。实际完成的功能为将28*28的图像矩阵转换成1*784的一维向量。</span></span><br><span class="line"><span class="comment">#FashionMnist数据集为28*28=784的灰度图像，共有10个分类，因此为784*10的线性层</span></span><br><span class="line"><span class="comment">#class torch.nn.Linear(in_features, out_features, bias=True)</span></span><br><span class="line"><span class="comment">#Linear的两个参数：weight和bias</span></span><br><span class="line"><span class="comment">#定义网络结构</span></span><br><span class="line">net = nn.Sequential(</span><br><span class="line">    nn.Flatten(),</span><br><span class="line">    nn.Linear(<span class="number">784</span>, <span class="number">10</span>)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">#网络权值初始化</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">init_weights</span>(<span class="params">m</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">type</span>(m) == nn.Linear:</span><br><span class="line">        nn.init.normal_(m.weight, <span class="number">0</span>, <span class="number">0.01</span>)</span><br><span class="line">net.apply(init_weights)</span><br></pre></td></tr></table></div></figure>
<p>通过阅读代码可以发现在顺序容器nn.Sequential里面并没有定义和Softmax相关的层次，实际上Pytorch实现中将交叉熵损失和softmax结合在了一起，网络采用具有10个输出的线性模型即可。</p>

        <h4 id="五、定义优化器与损失函数">
          <a href="#五、定义优化器与损失函数" class="heading-link"><i class="fas fa-link"></i></a><a href="#五、定义优化器与损失函数" class="headerlink" title="五、定义优化器与损失函数"></a>五、定义优化器与损失函数</h4>
      <p>使用交叉熵损失函数度量预测概率的准确性。并使用随机梯度下降作为模型的优化器。</p>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#定义损失函数</span></span><br><span class="line">loss = torch.nn.CrossEntropyLoss()</span><br><span class="line"><span class="comment">#定义优化器</span></span><br><span class="line">trainer = torch.optim.SGD(net.parameters(), lr=<span class="number">0.1</span>)</span><br></pre></td></tr></table></div></figure>


        <h4 id="六、定义训练器与训练函数">
          <a href="#六、定义训练器与训练函数" class="heading-link"><i class="fas fa-link"></i></a><a href="#六、定义训练器与训练函数" class="headerlink" title="六、定义训练器与训练函数"></a>六、定义训练器与训练函数</h4>
      <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_epoch_ch3</span>(<span class="params">net, train_iter, loss, updater</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(net, torch.nn.Module):</span><br><span class="line">        net.train()</span><br><span class="line">    <span class="comment">#统计每一个epoch,损失函数总和、预测正确的数量、样本总数</span></span><br><span class="line">    metric = Accumulator(<span class="number">3</span>)</span><br><span class="line">    <span class="keyword">for</span> X, y <span class="keyword">in</span> train_iter:</span><br><span class="line">        y_hat = net(X)<span class="comment">#预测值</span></span><br><span class="line">        l = loss(y_hat, y)<span class="comment">#计算交叉熵损失</span></span><br><span class="line">        updater.zero_grad()<span class="comment">#</span></span><br><span class="line">        l.backward()</span><br><span class="line">        updater.step()</span><br><span class="line">        metric.add(l, accuracy(y_hat, y), y.numel())</span><br><span class="line">    <span class="comment">#返回训练损失和训练准确率</span></span><br><span class="line">    <span class="keyword">return</span> metric[<span class="number">0</span>] / metric[<span class="number">2</span>], metric[<span class="number">1</span>] / metric[<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_ch3</span>(<span class="params">net, train_iter, test_iter, loss, num_epochs, updater</span>):</span></span><br><span class="line">    <span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">        <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">            train_metrics = train_epoch_ch3(net, train_iter, loss, updater)</span><br><span class="line">            test_acc = evaluate_accuracy(net, test_iter)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;epoch:<span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>,训练集损失:<span class="subst">&#123;train_metrics[<span class="number">0</span>]&#125;</span>,训练集准确率:<span class="subst">&#123;train_metrics[<span class="number">1</span>]&#125;</span>,测试集准确率:<span class="subst">&#123;test_acc&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></div></figure>


        <h4 id="七、数据加载与调用训练器进行训练">
          <a href="#七、数据加载与调用训练器进行训练" class="heading-link"><i class="fas fa-link"></i></a><a href="#七、数据加载与调用训练器进行训练" class="headerlink" title="七、数据加载与调用训练器进行训练"></a>七、数据加载与调用训练器进行训练</h4>
      <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#加载数据</span></span><br><span class="line">batch_size = <span class="number">256</span></span><br><span class="line">train_iter, test_iter = load_data_fashion_mnist(batch_size)</span><br><span class="line">num_epochs = <span class="number">100</span></span><br><span class="line"><span class="comment">#开始训练</span></span><br><span class="line">train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)</span><br></pre></td></tr></table></div></figure>

        <h4 id="八、结果展示">
          <a href="#八、结果展示" class="heading-link"><i class="fas fa-link"></i></a><a href="#八、结果展示" class="headerlink" title="八、结果展示"></a>八、结果展示</h4>
      <p><img src="/images/softmax-result.png" alt="upload successful"></p>

        <h4 id="九、总结">
          <a href="#九、总结" class="heading-link"><i class="fas fa-link"></i></a><a href="#九、总结" class="headerlink" title="九、总结"></a>九、总结</h4>
      <p>如结果图展示，仅仅在线性模型的基础上加上一层Softmax并采用交叉熵损失即可实现分类任务。但是准确率较低只有0.85左右。以后可以尝试更多的Epoch和更深的网络层次查看是否可以达到更强的效果。</p>
</div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2021/09/02/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E7%9A%84%E6%90%AD%E5%BB%BA-1/">深度学习环境的搭建</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">发表于</span><span class="post-meta-item__value">2021-09-02</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">更新于</span><span class="post-meta-item__value">2021-09-03</span></span></div></header><div class="post-body"><div class="post-excerpt">
        <h4 id="前言">
          <a href="#前言" class="heading-link"><i class="fas fa-link"></i></a><a href="#前言" class="headerlink" title="前言"></a>前言</h4>
      <p>总算是研究生开学了，之前在家混吃等死混了整整9个月也没学到什么有用的东西，<del>停止摸鱼永远从明天开始。</del>进入实验室的第一个小任务就是搭建深度学习的相关环境，由于之前毕设有过相关的经验所以完成起来困难不是很大。问了下师兄师姐的环境是  </p>
<blockquote>
<ul>
<li>Python版本：3.6.0  </li>
<li>Tensorflow版本：1.14  </li>
</ul>
</blockquote>

        <h4 id="1-Python的安装">
          <a href="#1-Python的安装" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-Python的安装" class="headerlink" title="1 Python的安装"></a>1 Python的安装</h4>
      
        <h5 id="1-1-Anaconda的安装与使用">
          <a href="#1-1-Anaconda的安装与使用" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-1-Anaconda的安装与使用" class="headerlink" title="1.1 Anaconda的安装与使用"></a>1.1 Anaconda的安装与使用</h5>
      <p>个人理解Anaconda是一个软件包管理工具，可以根据实际需要建立多个不同版本、不同软件包的虚拟环境。在代码编辑器如Pycharm中可以方便的切换环境。<br>在官网下载最新的版本。Anaconda下载地址：<span class="exturl"><a class="exturl__link" target="_blank" rel="noopener" href="https://www.anaconda.com/download/">https://www.anaconda.com/download/</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>，建议安装路径不要有中文，目录不要放得太深。最好更改pip源和conda源为国内服务器用以加速后期库的下载。</p>

        <h5 id="1-2-修改pip和conda的镜像源">
          <a href="#1-2-修改pip和conda的镜像源" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-2-修改pip和conda的镜像源" class="headerlink" title="1.2 修改pip和conda的镜像源"></a>1.2 修改pip和conda的镜像源</h5>
      <p>由于一些<del>不可抗力</del>，直接从pip和conda下载一些库可能会有点慢，因此有必要将pip和conda修改为国内镜像源以加速下载。  </p>

        <h6 id="1-2-1-修改pip镜像源">
          <a href="#1-2-1-修改pip镜像源" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-2-1-修改pip镜像源" class="headerlink" title="1.2.1 修改pip镜像源"></a>1.2.1 修改pip镜像源</h6>
      <p>在 user 目录中创建一个 pip 目录，如： C:\Users\xx\pip，xx是用户名，新建文件pip.ini（建议先新建成 .txt 文件，之后将后缀名改回），内容如下：  </p>
<figure class="highlight plaintext"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[global]</span><br><span class="line">timeout = 6000</span><br><span class="line">index-url = https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class="line">trusted-host = https://pypi.tuna.tsinghua.edu.cn</span><br></pre></td></tr></table></div></figure>

<p><img src="/images/%E6%A1%86%E6%9E%B6%E6%90%AD%E5%BB%BA1.png" alt="upload successful">  </p>

        <h6 id="1-2-2-修改conda镜像源">
          <a href="#1-2-2-修改conda镜像源" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-2-2-修改conda镜像源" class="headerlink" title="1.2.2 修改conda镜像源"></a>1.2.2 修改conda镜像源</h6>
      <p>进入conda的命令行终端，输入以下命令（逐条执行）:<br><img src="/images/%E6%A1%86%E6%9E%B6%E6%90%AD%E5%BB%BA2.png" alt="upload successful">  </p>
<figure class="highlight plaintext"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</span><br><span class="line">conda config --set show_channel_urls yes</span><br></pre></td></tr></table></div></figure>


<p>打开c:\users\系统用户名 目录，找到.condarc文件。.condarc 内容如下，表示成功：</p>
<p><img src="/images/%E6%A1%86%E6%9E%B6%E6%90%AD%E5%BB%BA3.png" alt="upload successful">  </p>

        <h5 id="1-3-建立Python环境">
          <a href="#1-3-建立Python环境" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-3-建立Python环境" class="headerlink" title="1.3 建立Python环境"></a>1.3 建立Python环境</h5>
      <p>镜像源设置完毕之后就可以进行Python环境的设置了，在Anaconda软件中选择environments，点击create建立，并选择Python版本为所需版本（本次选择的版本是3.6，在帮同学搭建的时候出现了下载最新版Anaconda里面只有python3.8版本的问题，实测可以先选择3.8版本然后再降级）。  </p>
<p><img src="/images/%E6%A1%86%E6%9E%B6%E6%90%AD%E5%BB%BA4.png" alt="upload successful">    </p>
<p>建立完成之后我们就可以打开终端用命令行的方法进行相关库的安装。  </p>

        <h5 id="1-4-Python降级与安装相关库">
          <a href="#1-4-Python降级与安装相关库" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-4-Python降级与安装相关库" class="headerlink" title="1.4 Python降级与安装相关库"></a>1.4 Python降级与安装相关库</h5>
      
        <h6 id="1-4-1-Python降级">
          <a href="#1-4-1-Python降级" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-4-1-Python降级" class="headerlink" title="1.4.1 Python降级"></a>1.4.1 Python降级</h6>
      <p>如上文所言，由于官网下载的最新版Anaconda只带了3.8版本的Python，而导师建议我们环境和师兄师姐们保持一致，需要降级到3.6版本。<br>还是进入到conda命令行工具，通过命令进入到已经搭建好的虚拟环境  </p>
<figure class="highlight plaintext"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda activate 之前建立的环境名  </span><br></pre></td></tr></table></div></figure>

<p><img src="/images/%E6%A1%86%E6%9E%B6%E6%90%AD%E5%BB%BA5.png" alt="upload successful"><br>输入以下命令，Python版本可以改成需要的版本号，如需要3.7可以直接将3.6改成3.7  </p>
<figure class="highlight plaintext"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install python==3.6</span><br></pre></td></tr></table></div></figure>

<p>回车执行之后可以看到版本号已经降级成功  </p>
<p><img src="/images/%E6%A1%86%E6%9E%B6%E6%90%AD%E5%BB%BA6.png" alt="upload successful">  </p>

        <h6 id="1-4-2-安装Tensorflow">
          <a href="#1-4-2-安装Tensorflow" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-4-2-安装Tensorflow" class="headerlink" title="1.4.2 安装Tensorflow"></a>1.4.2 安装Tensorflow</h6>
      <pre><code>pip install tensorflow==1.14(版本号可改成需要的版本)
</code></pre>
<p>输入pip list查看已经安装的包列表，已经有了tensorflow1.14至此安装结束</p>
<p><img src="/images/%E6%A1%86%E6%9E%B6%E6%90%AD%E5%BB%BA7.png" alt="upload successful"><br>PS：看网上有问题说numpy版本需要和tensorflow版本匹配，高版本的numpy可能会出现问题，由于我还没尝试使用因此暂且搁置，有问题再填坑  </p>

        <h4 id="2-编译器Pycharm的使用">
          <a href="#2-编译器Pycharm的使用" class="heading-link"><i class="fas fa-link"></i></a><a href="#2-编译器Pycharm的使用" class="headerlink" title="2 编译器Pycharm的使用"></a>2 编译器Pycharm的使用</h4>
      
        <h6 id="1-2-1-安装Pycharm">
          <a href="#1-2-1-安装Pycharm" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-2-1-安装Pycharm" class="headerlink" title="1.2.1 安装Pycharm"></a>1.2.1 安装Pycharm</h6>
      <p>没什么，安装community社区版本即可  </p>

        <h6 id="1-2-2-在Pycharm中设置解释器为conda虚拟环境">
          <a href="#1-2-2-在Pycharm中设置解释器为conda虚拟环境" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-2-2-在Pycharm中设置解释器为conda虚拟环境" class="headerlink" title="1.2.2 在Pycharm中设置解释器为conda虚拟环境"></a>1.2.2 在Pycharm中设置解释器为conda虚拟环境</h6>
      <p>File-&gt;Settings-&gt;Project:code-&gt;Project Interpreter点击add  </p>
<p><img src="/images/%E6%A1%86%E6%9E%B6%E6%90%AD%E5%BB%BA8.png" alt="upload successful"><br>选择conda environments,在existing enviroments中找到所创建环境名文件夹下面的Python.exe再点击ok和apply即可。</p>
<p><img src="/images/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA8.png" alt="upload successful">  </p>

        <h4 id="结语">
          <a href="#结语" class="heading-link"><i class="fas fa-link"></i></a><a href="#结语" class="headerlink" title="结语"></a>结语</h4>
      <p>至此整个环境应该就已经搭建完毕，<del>出现什么问题以后会来填坑罢。希望以后也能保持博客的高强度更新。</del></p>
</div></div></article></section><nav class="paginator"><div class="paginator-inner"><span class="page-number current">1</span></div></nav></div></div><div class="sidebar-wrap" id="sidebar-wrap"><aside class="sidebar" id="sidebar"><section class="sidebar-toc hide"></section><!-- ov = overview--><section class="sidebar-ov"><div class="sidebar-ov-author"><div class="sidebar-ov-author__avatar"><img class="sidebar-ov-author__avatar_img" src="/images/icons/photo.png" alt="avatar"></div><p class="sidebar-ov-author__text">To be a great person.</p></div><div class="sidebar-ov-cc"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" target="_blank" rel="noopener" data-popover="知识共享许可协议" data-popover-pos="up"><img src="/images/cc-by-nc-sa.svg"></a></div></section></aside></div><div class="clearfix"></div></div></main><footer class="footer" id="footer"><div class="footer-inner"><div><span>Copyright © 2021</span><span class="footer__icon"><i class="fas fa-heart"></i></span><span>Strive</span></div><div><span>由 <a href="http://hexo.io/" title="Hexo" target="_blank" rel="noopener">Hexo</a> 强力驱动</span><span> v5.4.0</span><span class="footer__devider">|</span><span>主题 - <a href="https://github.com/liuyib/hexo-theme-stun/" title="Stun" target="_blank" rel="noopener">Stun</a></span><span> v2.6.2</span></div></div></footer><div class="loading-bar" id="loading-bar"><div class="loading-bar__progress"></div></div><div class="back2top" id="back2top"><span class="back2top__icon"><i class="fas fa-rocket"></i></span></div></div><script src="https://cdn.jsdelivr.net/npm/jquery@v3.4.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.ui.min.js"></script><script src="/js/utils.js?v=2.6.2"></script><script src="/js/stun-boot.js?v=2.6.2"></script><script src="/js/scroll.js?v=2.6.2"></script><script src="/js/header.js?v=2.6.2"></script><script src="/js/sidebar.js?v=2.6.2"></script></body></html>
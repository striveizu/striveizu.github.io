<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><link rel="icon" href="/images/icons/favicon-16x16.png?v=2.6.2" type="image/png" sizes="16x16"><link rel="icon" href="/images/icons/favicon-32x32.png?v=2.6.2" type="image/png" sizes="32x32"><meta name="description" content="踩坑记录001       回家混了好几天才开始干点正事，开摆！ 新年的第一篇博客本来想写一下Ubuntu系统的安装、Nvidia驱动的安装和CenterNet运行环境的配置。可是在学校的时候一直在混，Liunx上写博客还没有找到很方便的方式，踩过的坑很多都忘记了。 以后踩坑一定要及时记录！ 由于一两个月没有搞代码了，刚回家就碰见了个非常脑残小儿科的问题却一">
<meta property="og:type" content="article">
<meta property="og:title" content="深度学习踩坑记录001——训练集loss正常下降，测试集一动不动">
<meta property="og:url" content="https://striveizu.top/2022/01/28/caikeng001/index.html">
<meta property="og:site_name" content="Strive&#39;s Blog">
<meta property="og:description" content="踩坑记录001       回家混了好几天才开始干点正事，开摆！ 新年的第一篇博客本来想写一下Ubuntu系统的安装、Nvidia驱动的安装和CenterNet运行环境的配置。可是在学校的时候一直在混，Liunx上写博客还没有找到很方便的方式，踩过的坑很多都忘记了。 以后踩坑一定要及时记录！ 由于一两个月没有搞代码了，刚回家就碰见了个非常脑残小儿科的问题却一">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://striveizu.top/2022/01/28/caikeng001/image-20220128123827445.png">
<meta property="og:image" content="https://striveizu.top/2022/01/28/caikeng001/image-20220128115856272.png">
<meta property="og:image" content="https://striveizu.top/2022/01/28/caikeng001/image-20220128140116390.png">
<meta property="article:published_time" content="2022-01-28T03:25:00.000Z">
<meta property="article:modified_time" content="2022-03-06T02:12:10.176Z">
<meta property="article:author" content="Strive">
<meta property="article:tag" content="深度学习踩坑记录">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://striveizu.top/2022/01/28/caikeng001/image-20220128123827445.png"><title>深度学习踩坑记录001——训练集loss正常下降，测试集一动不动 | Strive's Blog</title><link ref="canonical" href="https://striveizu.top/2022/01/28/caikeng001/"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.12.1/css/all.min.css" type="text/css"><link rel="stylesheet" href="/css/index.css?v=2.6.2"><script>var Stun = window.Stun || {};
var CONFIG = {
  root: '/',
  algolia: undefined,
  assistSearch: undefined,
  fontIcon: {"prompt":{"success":"fas fa-check-circle","info":"fas fa-arrow-circle-right","warning":"fas fa-exclamation-circle","error":"fas fa-times-circle"},"copyBtn":"fas fa-copy"},
  sidebar: {"offsetTop":"20px","tocMaxDepth":6},
  header: {"enable":true,"showOnPost":true,"scrollDownIcon":true},
  postWidget: {"endText":true},
  nightMode: {"enable":true},
  back2top: {"enable":true},
  codeblock: {"style":"default","highlight":"light","wordWrap":false},
  reward: false,
  fancybox: false,
  zoomImage: {"gapAside":"20px"},
  galleryWaterfall: undefined,
  lazyload: false,
  pjax: undefined,
  externalLink: {"icon":{"enable":true,"name":"fas fa-external-link-alt"}},
  shortcuts: undefined,
  prompt: {"copyButton":"复制","copySuccess":"复制成功","copyError":"复制失败"},
  sourcePath: {"js":"js","css":"css","images":"images"},
};

window.CONFIG = CONFIG;</script><meta name="generator" content="Hexo 5.4.0"></head><body><div class="container" id="container"><header class="header" id="header"><div class="header-inner"><nav class="header-nav header-nav--fixed"><div class="header-nav-inner"><div class="header-nav-menubtn"><i class="fas fa-bars"></i></div><div class="header-nav-menu"><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/"><span class="header-nav-menu-item__icon"><i class="fas fa-home"></i></span><span class="header-nav-menu-item__text">首页</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/about/"><span class="header-nav-menu-item__icon"><i class="fas fa-address-card"></i></span><span class="header-nav-menu-item__text">关于</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="javascript:;" onclick="return false;"><span class="header-nav-menu-item__icon"><i class="fas fa-edit"></i></span><span class="header-nav-menu-item__text">文章</span></a><div class="header-nav-submenu"><div class="header-nav-submenu-item"><a class="header-nav-submenu-item__link" href="/archives/"><span class="header-nav-submenu-item__icon"><i class="fas fa-folder-open"></i></span><span class="header-nav-submenu-item__text">归档</span></a></div><div class="header-nav-submenu-item"><a class="header-nav-submenu-item__link" href="/categories/"><span class="header-nav-submenu-item__icon"><i class="fas fa-layer-group"></i></span><span class="header-nav-submenu-item__text">分类</span></a></div><div class="header-nav-submenu-item"><a class="header-nav-submenu-item__link" href="/tags/"><span class="header-nav-submenu-item__icon"><i class="fas fa-tags"></i></span><span class="header-nav-submenu-item__text">标签</span></a></div></div></div></div><div class="header-nav-mode"><div class="mode"><div class="mode-track"><span class="mode-track-moon"></span><span class="mode-track-sun"></span></div><div class="mode-thumb"></div></div></div></div></nav><div class="header-banner"><div class="header-banner-info"><div class="header-banner-info__title">Strive's Blog</div><div class="header-banner-info__subtitle">你我期许的绝非遥不可及</div></div><div class="header-banner-arrow"><div class="header-banner-arrow__icon"><i class="fas fa-angle-down"></i></div></div></div></div></header><main class="main" id="main"><div class="main-inner"><div class="content-wrap" id="content-wrap"><div class="content" id="content"><!-- Just used to judge whether it is an article page--><div id="is-post"></div><div class="post"><header class="post-header"><h1 class="post-title">深度学习踩坑记录001——训练集loss正常下降，测试集一动不动</h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">发表于</span><span class="post-meta-item__value">2022-01-28</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">更新于</span><span class="post-meta-item__value">2022-03-06</span></span></div></header><div class="post-body">
        <h3 id="踩坑记录001">
          <a href="#踩坑记录001" class="heading-link"><i class="fas fa-link"></i></a><a href="#踩坑记录001" class="headerlink" title="踩坑记录001"></a>踩坑记录001</h3>
      <p>回家混了好几天才开始干点正事，开摆！</p>
<p>新年的第一篇博客本来想写一下Ubuntu系统的安装、Nvidia驱动的安装和CenterNet运行环境的配置。可是在学校的时候一直在混，Liunx上写博客还没有找到很方便的方式，踩过的坑很多都忘记了。</p>
<p><strong>以后踩坑一定要及时记录</strong>！</p>
<p>由于一两个月没有搞代码了，刚回家就碰见了个非常脑残小儿科的问题却一直没有解决。</p>

        <h4 id="问题描述">
          <a href="#问题描述" class="heading-link"><i class="fas fa-link"></i></a><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h4>
      <p>回家做一个ResNet50的CIFAR10分类找找之前遗忘的知识，出现了训练集的loss正常下降、准确率正常上升。而测试集的loss却几乎不下降甚至还有反增，准确率保持非常低的水平不变。如下图所示：</p>
<p><img src="/2022/01/28/caikeng001/image-20220128123827445.png" alt="image-20220128123827445"></p>
<p>可见训练集准确度已经到了很高的程度，但是测试集的loss和准确率几乎没有什么变化。仔细检查代码（指查了三天）发现在数据的预处理部分，训练集做了Resize、随机翻转和均值化操作，但是测试集没有作任何处理。</p>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">myTransforms = transforms.Compose([</span><br><span class="line">    transforms.Resize((<span class="number">32</span>, <span class="number">32</span>)),</span><br><span class="line">    transforms.RandomHorizontalFlip(p=<span class="number">0.5</span>),</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize((<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>), (<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>))</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据加载部分</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_dataset</span>(<span class="params">batch_size</span>):</span></span><br><span class="line">    train_set = torchvision.datasets.CIFAR10(</span><br><span class="line">        root=<span class="string">&#x27;../data/cifar&#x27;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>, transform=myTransforms)</span><br><span class="line">    test_set = torchvision.datasets.CIFAR10(</span><br><span class="line">        root=<span class="string">&#x27;../data/cifar&#x27;</span>, train=<span class="literal">False</span>, download=<span class="literal">True</span>, transform=transforms.ToTensor())</span><br><span class="line">    train_iter = data.DataLoader(train_set, batch_size=batch_size, shuffle=<span class="literal">True</span>, num_workers=<span class="number">2</span>)</span><br><span class="line">    test_iter = data.DataLoader(test_set, batch_size=batch_size, shuffle=<span class="literal">True</span>, num_workers=<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> train_iter, test_iter</span><br></pre></td></tr></table></div></figure>

<p>即问题出在训练集和测试集没有作相同的预处理。引用知乎一个很恰当的比喻是：<strong>你复习了一整晚的高数课本，可是第二天考线性代数，虽然二者都属于数学范畴，但是你拿高数知识解线代怎么能做的好呢？</strong>对数据集作预处理，如均值化操作，实际上对数据的分布作了改变。训练集训练的是一个数据分布，直接拿训练的网络对另外一个数据分布的测试集作测试，效果肯定不好。</p>

        <h4 id="问题解决方法">
          <a href="#问题解决方法" class="heading-link"><i class="fas fa-link"></i></a><a href="#问题解决方法" class="headerlink" title="问题解决方法"></a>问题解决方法</h4>
      <p>将数据加载的预处理统一，训练集和测试集使用相同的预处理方式。</p>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数据加载部分</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_dataset</span>(<span class="params">batch_size</span>):</span></span><br><span class="line">    train_set = torchvision.datasets.CIFAR10(</span><br><span class="line">        root=<span class="string">&#x27;../data/cifar&#x27;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>, transform=myTransforms)</span><br><span class="line">    test_set = torchvision.datasets.CIFAR10(</span><br><span class="line">        root=<span class="string">&#x27;../data/cifar&#x27;</span>, train=<span class="literal">False</span>, download=<span class="literal">True</span>, transform=myTransforms)</span><br><span class="line">    train_iter = data.DataLoader(train_set, batch_size=batch_size, shuffle=<span class="literal">True</span>, num_workers=<span class="number">2</span>)</span><br><span class="line">    test_iter = data.DataLoader(test_set, batch_size=batch_size, shuffle=<span class="literal">True</span>, num_workers=<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> train_iter, test_iter</span><br></pre></td></tr></table></div></figure>

<p><img src="/2022/01/28/caikeng001/image-20220128115856272.png" alt="image-20220128115856272"></p>
<p>测试集准确率就正常上升了。</p>

        <h4 id="学习与反思">
          <a href="#学习与反思" class="heading-link"><i class="fas fa-link"></i></a><a href="#学习与反思" class="headerlink" title="学习与反思"></a>学习与反思</h4>
      <p>借用知乎回答“深度学习中为什么要对测试集进行与训练集一样的数据预处理？”</p>
<p>作者：深海<br>链接：<span class="exturl"><a class="exturl__link" target="_blank" rel="noopener" href="https://www.zhihu.com/question/479694291/answer/2061254022">https://www.zhihu.com/question/479694291/answer/2061254022</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></p>
<p>我们拿标准化举例，标准化也是数据预处理的过程，我们假设将要标准化的某个特征服从高斯分布。</p>
<p>在神经网络中也可以看作是使网络收敛更加稳定的trick（因为标准化后大部分数值落在一定区间内）。</p>
<p>我们只能通过训练集获得到数据中该特征的所有可能的情况，我们假设我们拿到的训练集是足够有代表性的，能够从训练集中尽可能逼近数据本身服从的概率分布（这也就是为什么扩充数据能够提升模型泛化能力，我们拿到的数据越多，越能接近数据本身的分布，如果我们拿到全量数据，那么本身的分布就确定下来了，假设数据的某个特征服从高斯分布，那么它的均值和方差也确定了，如果我们能拿到全量数据，那也就没必要做机器学习了）。</p>
<p>所以我们是拿训练集中数据的某个特征代表了全部数据的这个特征，用它的均值和方差代表了全部数据的均值和方差。这就很容易理解了，测试集要使用训练集的均值和方差进行标准化，不就是在用我们假设的数据特征服从的均值和方差进行标准化吗？</p>
<p>所以不只是深度学习，传统机器学习算法的预处理也需要这么做。深度学习做了标准化后能够对网络的训练有一些益处罢了，这也是为什么做bn，ln的原因，以及网络中用到的各种归一化的trick，对深度学习中网络优化过程中数值的稳定性有一定的帮助。</p>
<p>寒假回家第6天了，今天才刚开始做了点东西（虽然没有什么卵用）。除夕之前一定要把DLA跑通。。。。。</p>
<p><img src="/2022/01/28/caikeng001/image-20220128140116390.png" alt="image-20220128140116390"></p>
</div><footer class="post-footer"><div class="post-ending ending"><div class="ending__text">------ 本文结束，感谢您的阅读 ------</div></div><div class="post-copyright copyright"><div class="copyright-author"><span class="copyright-author__name">本文作者: </span><span class="copyright-author__value"><a href="https://striveizu.top">Strive</a></span></div><div class="copyright-link"><span class="copyright-link__name">本文链接: </span><span class="copyright-link__value"><a href="https://striveizu.top/2022/01/28/caikeng001/">https://striveizu.top/2022/01/28/caikeng001/</a></span></div><div class="copyright-notice"><span class="copyright-notice__name">版权声明: </span><span class="copyright-notice__value">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" rel="external nofollow" target="_blank">BY-NC-SA</a> 许可协议。转载请注明出处！</span></div></div><div class="post-tags"><span class="post-tags-item"><span class="post-tags-item__icon"><i class="fas fa-tag"></i></span><a class="post-tags-item__link" href="https://striveizu.top/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/">深度学习踩坑记录</a></span></div><nav class="post-paginator paginator"><div class="paginator-prev"><a class="paginator-prev__link" href="/2022/01/28/DLA/"><span class="paginator-prev__icon"><i class="fas fa-angle-left"></i></span><span class="paginator-prev__text">DLA模型</span></a></div><div class="paginator-next"><a class="paginator-next__link" href="/2022/01/17/CenterNet/"><span class="paginator-prev__text">CenterNet学习笔记</span><span class="paginator-next__icon"><i class="fas fa-angle-right"></i></span></a></div></nav></footer></div></div></div><div class="sidebar-wrap" id="sidebar-wrap"><aside class="sidebar" id="sidebar"><div class="sidebar-nav"><span class="sidebar-nav-toc current">文章目录</span><span class="sidebar-nav-ov">站点概览</span></div><section class="sidebar-toc"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95001"><span class="toc-number">1.</span> <span class="toc-text">
          踩坑记录001</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%97%AE%E9%A2%98%E6%8F%8F%E8%BF%B0"><span class="toc-number">1.1.</span> <span class="toc-text">
          问题描述</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95"><span class="toc-number">1.2.</span> <span class="toc-text">
          问题解决方法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AD%A6%E4%B9%A0%E4%B8%8E%E5%8F%8D%E6%80%9D"><span class="toc-number">1.3.</span> <span class="toc-text">
          学习与反思</span></a></li></ol></li></ol></section><!-- ov = overview--><section class="sidebar-ov hide"><div class="sidebar-ov-author"><div class="sidebar-ov-author__avatar"><img class="sidebar-ov-author__avatar_img" src="/images/icons/photo.png" alt="avatar"></div><p class="sidebar-ov-author__text">To be a great person.</p></div><div class="sidebar-ov-cc"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" target="_blank" rel="noopener" data-popover="知识共享许可协议" data-popover-pos="up"><img src="/images/cc-by-nc-sa.svg"></a></div></section><div class="sidebar-reading"><div class="sidebar-reading-info"><span class="sidebar-reading-info__text">你已阅读了 </span><span class="sidebar-reading-info__num">0</span><span class="sidebar-reading-info__perc">%</span></div><div class="sidebar-reading-line"></div></div></aside></div><div class="clearfix"></div></div></main><footer class="footer" id="footer"><div class="footer-inner"><div><span>Copyright © 2023</span><span class="footer__icon"><i class="fas fa-heart"></i></span><span>Strive</span></div><div><span>由 <a href="http://hexo.io/" title="Hexo" target="_blank" rel="noopener">Hexo</a> 强力驱动</span><span> v5.4.0</span><span class="footer__devider">|</span><span>主题 - <a href="https://github.com/liuyib/hexo-theme-stun/" title="Stun" target="_blank" rel="noopener">Stun</a></span><span> v2.6.2</span></div></div></footer><div class="loading-bar" id="loading-bar"><div class="loading-bar__progress"></div></div><div class="back2top" id="back2top"><span class="back2top__icon"><i class="fas fa-rocket"></i></span></div></div><script src="https://cdn.jsdelivr.net/npm/jquery@v3.4.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.ui.min.js"></script><script src="/js/utils.js?v=2.6.2"></script><script src="/js/stun-boot.js?v=2.6.2"></script><script src="/js/scroll.js?v=2.6.2"></script><script src="/js/header.js?v=2.6.2"></script><script src="/js/sidebar.js?v=2.6.2"></script></body></html>